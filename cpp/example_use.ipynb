{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "from time import perf_counter\n",
    "from multiprocessing import shared_memory\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from data import get_ref_spectra_from_df, batches, mkdir, spectra_peaks_to_tensor\n",
    "from kernel import compile\n",
    "from cosine import similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define constants\n",
    "tolerance: float = 0.1\n",
    "shift: float = 0\n",
    "mz_power: float = 0\n",
    "int_power: float = 1\n",
    "\n",
    "## How many pairs per batch. Has to be a power of 2.\n",
    "# Hardware specific - An RTX2070 works best at around 1024 * 2\n",
    "# But Colab T4 GPU might work best at 1024 * 4\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# MATCH_LIMIT specifies max how many mz-mz pairs we could consider for each RQ pair, before we sort and filter. \n",
    "# E.g. a value of 256 usually causes around ~0.003% of RQ pairs to \"overflow\".\n",
    "# The overflown RQ scores will be strictly less than or equal to perfectly accurate score.\n",
    "# The mean absolute difference at 256, for all overflown pairs is on the order of ~1e-3\n",
    "# Small values of MATCH_LIMIT (e.g. 128, 64,) cause a dramatic speedup in the processing speed.\n",
    "MATCH_LIMIT = 256\n",
    "\n",
    "## GPU-specific constants\n",
    "THREADS_PER_BLOCK = (32, 32)\n",
    "BLOCKS_PER_GRID_X = math.ceil(BATCH_SIZE / THREADS_PER_BLOCK[0])\n",
    "BLOCKS_PER_GRID_Y = math.ceil(BATCH_SIZE / THREADS_PER_BLOCK[1])\n",
    "BLOCKS_PER_GRID = (BLOCKS_PER_GRID_X, BLOCKS_PER_GRID_Y)\n",
    "\n",
    "# Since Greedy cosine is an unstable algorithm, because approximate mz-mz values do not\n",
    "# result in approximately the same scores and number of matches.\n",
    "# So we need to use fp64 to minimize the deviation as much as possible.\n",
    "# Using float32 causes a significant speedup in the processing speed.\n",
    "dtype = 'float64'\n",
    "\n",
    "# Data path\n",
    "reference_csv_file = \"data/input/example_dataset_tornike.csv\"\n",
    "query_csv_file = \"data/input/example_dataset_tornike.csv\"\n",
    "output_dir = 'data/output/'\n",
    "\n",
    "# Limits\n",
    "# We consider only first LIMIT number of entries in CSVs\n",
    "LIMIT = 2048\n",
    "\n",
    "# For keeping track of experiments\n",
    "CONFIG = dict(\n",
    "    tolerance = tolerance,\n",
    "    shift = shift,\n",
    "    mz_power = mz_power,\n",
    "    int_power = int_power,\n",
    "    match_limit = MATCH_LIMIT,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    limit = LIMIT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:03<00:00, 638.48it/s] \n",
      "100%|██████████| 2048/2048 [00:00<00:00, 4576.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 100001 references and 100001 queries\n"
     ]
    }
   ],
   "source": [
    "# We load CSV files using multiple threads\n",
    "ref_spectra_df_path = Path(reference_csv_file)\n",
    "ref_spectra_df = pd.read_csv(ref_spectra_df_path)\n",
    "references = get_ref_spectra_from_df(ref_spectra_df, limit=LIMIT)\n",
    "\n",
    "query_spectra_df_path = Path(query_csv_file)\n",
    "query_spectra_df = pd.read_csv(query_spectra_df_path)\n",
    "queries = get_ref_spectra_from_df(query_spectra_df, limit=LIMIT)\n",
    "\n",
    "print(f\"We have {len(ref_spectra_df)} references and {len(query_spectra_df)} queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0    b'NVIDIA GeForce RTX 2070 with Max-Q Design'                              [SUPPORTED]\n",
      "                      Compute Capability: 7.5\n",
      "                           PCI Device ID: 0\n",
      "                              PCI Bus ID: 1\n",
      "                                    UUID: GPU-f6e241c8-f0ad-720e-be22-2713a6b0868d\n",
      "                                Watchdog: Enabled\n",
      "             FP32/FP64 Performance Ratio: 32\n",
      "Summary:\n",
      "\t1/1 devices are supported\n"
     ]
    }
   ],
   "source": [
    "# Numba Just-in-time compiles our kernel and bakes in our constants for performance.\n",
    "kernel = compile(tolerance=tolerance, shift=shift, \n",
    "                 mz_power=mz_power, int_power=int_power, \n",
    "                 match_limit=MATCH_LIMIT, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches:  4\n",
      "Total pairs considered: 1993 * 1993 = 3972049\n",
      "Since 1993 isn't divisible by BATCH_SIZE, last batch will have 969 empty ROWS at the end\n",
      "Since 1993 isn't divisible by BATCH_SIZE, last batch will have 969 empty COLUMNS at the end\n"
     ]
    }
   ],
   "source": [
    "output_dir = mkdir(output_dir)\n",
    "\n",
    "TOTAL_BATCHES_X = math.ceil( len(references) / BATCH_SIZE )\n",
    "TOTAL_BATCHES_Y = math.ceil( len(queries) / BATCH_SIZE)\n",
    "TOTAL_BATCHES = TOTAL_BATCHES_X * TOTAL_BATCHES_Y\n",
    "print(\"Total batches: \", TOTAL_BATCHES)\n",
    "print(f\"Total pairs considered: {len(references)} * {len(queries)} = {len(references) * len(queries)}\")\n",
    "\n",
    "if len(references) % BATCH_SIZE != 0:\n",
    "    print(f\"Since {len(references)} isn't divisible by BATCH_SIZE, last batch will have {len(references) % BATCH_SIZE} empty ROWS at the end\")\n",
    "if len(queries) % BATCH_SIZE != 0:\n",
    "    print(f\"Since {len(queries)} isn't divisible by BATCH_SIZE, last batch will have {len(queries) % BATCH_SIZE} empty COLUMNS at the end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch all references: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch all references: 2it [00:00, 22.83it/s]\n",
      "Batch all queries: 2it [00:00, 18.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load each batch in memory so that we don't have to load any R,Q twice\n",
    "batches_r = []\n",
    "for rbatch in tqdm(batches(references, BATCH_SIZE), desc=\"Batch all references\"):\n",
    "    rspec, rlen = spectra_peaks_to_tensor(rbatch, dtype=dtype)\n",
    "    batches_r.append([rspec, rlen])\n",
    "\n",
    "batches_q = list()\n",
    "for qbatch in tqdm(batches(queries, BATCH_SIZE), desc=\"Batch all queries\"):\n",
    "    qspec, qlen  = spectra_peaks_to_tensor(qbatch, dtype=dtype)\n",
    "    batches_q.append([qspec, qlen])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand what we are doing here, let's take a look at this image below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![alt text](assets/cosine-batch-layout-grid.jpg \"Title\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1.5 million references and 100k arrays and want a stupidly large matrix of scores, with 1.5 million rows and 100k columns, where each matrix entry is a result of pairwise GreedyCosine. All entries are independent and can be computed in parallel. Even with high-CPU count (my machine has 8 CPU, estimate it takes 200 hours\n",
    "\n",
    "GPUs are fundamentally a large 2D grid of very small CPUs. There are several ways of making our problem \"fit\" to the enviroment of GPUs, and I have chosen the following layout as shown above.\n",
    "\n",
    "GPU can processes a single batch at a time - per-batch processing speed is near-instatanous, regardless of batch size, as long as the batch can fit into memory.\n",
    "\n",
    "So - every batch is a 2D grid of references and queries that will be compared pairwise by different threads. If we zoom into the batch#0, we see:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![alt text](assets/cosine-batch-layout-batch.jpg \"Title\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning that a GPU has a separate small CPU (thread) for every pair in the cartesian product of references and queries in that batch. We see that every thread takes in it's own reference and query and returns three values:\n",
    "score (float), num_matches (int, but casted to float), overflow (bool).\n",
    "\n",
    "If we further zoom into the first thread, we see this pseudo-code being executed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![alt text](assets/cosine-batch-layout-thread.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is what is called a CUDA kernel - and it is exactly the same for every single thread in all batches. What changes is the input data (per batch) and which reference and query we work with (per thread).\n",
    "\n",
    "The algorithm has two parts.\n",
    "\n",
    "First loop collects all possible mzmz pairs (up to MATCH_LIMIT size), and report an overflow if it happens.\n",
    "\n",
    "Second loop is essentially a bubble sort. Since \"sorted()\" isn't available to CUDA threads, we have to manually loop over the matches (nested loop) and, while we have left over scores:\n",
    "- Get largest score\n",
    "- Discard all other scores that have same index\n",
    "- We normalize the score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch all references: 2it [00:00, 30.31it/s]\n",
      "Batch all queries: 2it [00:00, 30.15it/s]\n"
     ]
    }
   ],
   "source": [
    "streams = [cuda.stream() for _ in range(TOTAL_BATCHES)]\n",
    "\n",
    "batches_r = []\n",
    "for rbatch in tqdm(batches(references, BATCH_SIZE), desc=\"Batch all references\"):\n",
    "    rspec, rlen = spectra_peaks_to_tensor(rbatch, dtype=dtype)\n",
    "    batches_r.append([rspec, rlen])\n",
    "\n",
    "batches_q = list()\n",
    "for qbatch in tqdm(batches(queries, BATCH_SIZE), desc=\"Batch all queries\"):\n",
    "    qspec, qlen  = spectra_peaks_to_tensor(qbatch, dtype=dtype)\n",
    "    batches_q.append([qspec, qlen])\n",
    "    \n",
    "batches_rq = list(product(batches_r, batches_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed at 2483338.3 pairs/sec\n",
      "Estimated 16.78hrs per 100k x 1.5mln\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "# We initialize a pool of 3 workers that will offload results to disk\n",
    "with ThreadPool(3) as pool:\n",
    "    # We loop over all batchs in sequence\n",
    "    for batch_i in tqdm(range(TOTAL_BATCHES)):\n",
    "        \n",
    "        # Each batch has own CUDA stream so that the GPU is as busy as possible\n",
    "        stream = streams[batch_i]\n",
    "        \n",
    "        # Shared memory allows pool workers to read array without copying it\n",
    "        out_shm = shared_memory.SharedMemory(create=True, size=(BATCH_SIZE * BATCH_SIZE * 2 * 4))\n",
    "        out = np.ndarray(shape=(BATCH_SIZE, BATCH_SIZE, 2), dtype='float32', buffer=out_shm.buf)\n",
    "        overflow_shm = shared_memory.SharedMemory(create=True, size=(BATCH_SIZE * BATCH_SIZE * 1 * 1))\n",
    "        overflow = np.ndarray(shape=(BATCH_SIZE, BATCH_SIZE, 1), dtype='uint8', buffer=overflow_shm.buf)\n",
    "\n",
    "        # We order empty space for results on GPU RAM\n",
    "        out_cu = cuda.device_array((BATCH_SIZE, BATCH_SIZE, 2), dtype='float32', stream=stream)\n",
    "        overflow_cu = cuda.device_array((BATCH_SIZE, BATCH_SIZE, 1), dtype='uint8', stream=stream)\n",
    "\n",
    "        # We get our batch and lengths (lengths are different for different spectra)\n",
    "        (rspec, rlen), (qspec, qlen) = batches_rq[batch_i]\n",
    "        lens = np.zeros((2, max(BATCH_SIZE, BATCH_SIZE)), 'int32')\n",
    "        lens[0,:len(rlen)] = rlen\n",
    "        lens[1,:len(qlen)] = qlen\n",
    "        \n",
    "        # We make sure main resources remain on CPU RAM\n",
    "        with cuda.pinned(rspec, qspec, lens, out, overflow,):\n",
    "            \n",
    "            # We order the stream to copy input data to GPU RAM\n",
    "            rspec_cu = cuda.to_device(rspec, stream=stream)\n",
    "            qspec_cu = cuda.to_device(qspec, stream=stream)\n",
    "            lens_cu = cuda.to_device(lens, stream=stream)\n",
    "            \n",
    "            # We order the stream to execute kernel (this is scheduled, it will execute, but we can't force it)\n",
    "            kernel(rspec_cu, qspec_cu,\n",
    "                    lens_cu,\n",
    "                    out_cu, overflow_cu,\n",
    "                    stream=stream)\n",
    "            \n",
    "            # We order a data return\n",
    "            out_cu.copy_to_host(out, stream=stream)\n",
    "            overflow_cu.copy_to_host(overflow, stream=stream)\n",
    "\n",
    "            # We create a function that will execute when this stream is done working\n",
    "            # It is important to be quick here - so main work of writing to disk\n",
    "            # Is handled by pool workers, not callback stream.\n",
    "            def end_of_stream_callback(*args):\n",
    "                def thread_worker(name1, name2):\n",
    "                    ex_shm = shared_memory.SharedMemory(name=name1)\n",
    "                    out = np.ndarray(shape=(BATCH_SIZE, BATCH_SIZE, 2), dtype=np.float32, buffer=ex_shm.buf)\n",
    "                    np.save(output_dir/f'{batch_i:05d}.score.npy', out)\n",
    "                    ex_shm.unlink()\n",
    "                    ex_shm = shared_memory.SharedMemory(name=name2)\n",
    "                    overflow = np.ndarray(shape=(BATCH_SIZE, BATCH_SIZE, 1), dtype=np.uint8, buffer=ex_shm.buf)\n",
    "                    np.save(output_dir/f'{batch_i:05d}.ovfl.npy', overflow)\n",
    "                    ex_shm.unlink()\n",
    "                    \n",
    "                pool.apply_async(\n",
    "                    thread_worker, \n",
    "                    args=[out_shm.name, overflow_shm.name], \n",
    "                    error_callback=lambda e: print(\"Thread error\", e)\n",
    "                )\n",
    "            stream.add_callback(\n",
    "                callback=end_of_stream_callback,\n",
    "            )\n",
    "\n",
    "# We wait for all streams to finish their work everywhere \n",
    "cuda.synchronize()\n",
    "\n",
    "# We can now calculate our performance fairly\n",
    "duration = perf_counter() - start\n",
    "persec = len(references) * len(queries) / duration\n",
    "print(f\"Speed at {persec:.1f} pairs/sec\")\n",
    "print(f\"Estimated {(100_000 * 1_500_000 / persec) / 3600:.2f}hrs per 100k x 1.5mln\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering and further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get any one specific R and Q similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REF 1337 and QUE 777: Score 0.0, Num Matches 0.0\n"
     ]
    }
   ],
   "source": [
    "def get_one_specific(\n",
    "    ref_idx,\n",
    "    que_idx,\n",
    ") -> tuple:\n",
    "\n",
    "    batch_idx_x = ref_idx // BATCH_SIZE\n",
    "    batch_idx_y = que_idx // BATCH_SIZE\n",
    "\n",
    "    batch_idx = batch_idx_x * TOTAL_BATCHES_Y + batch_idx_y\n",
    "    scores = np.load(output_dir / f'{batch_idx:05d}.score.npy')\n",
    "\n",
    "    ref_idx_batch = ref_idx % BATCH_SIZE\n",
    "    que_idx_batch = que_idx % BATCH_SIZE\n",
    "\n",
    "    score, num_matches = scores[ref_idx_batch, que_idx_batch]\n",
    "    return score, num_matches\n",
    "ref_idx = 1337\n",
    "que_idx = 777\n",
    "score, num_matches = get_one_specific(ref_idx, que_idx)\n",
    "print(f\"REF {ref_idx} and QUE {que_idx}: Score {score}, Num Matches {num_matches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query RQ pairs with condition on score\n",
    "\n",
    "This is still TODO on large outputs, since filtering gigabytes worth of numpy arrays will take forever. For now, CPU implementation should suffice - or we could integrate this \"filtering\" behaviour directly into Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference       UInt32\n",
      "Query           UInt32\n",
      "Score          Float32\n",
      "Num_Matches     UInt16\n",
      "dtype: object Memory  1.079728 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference</th>\n",
       "      <th>Query</th>\n",
       "      <th>Score</th>\n",
       "      <th>Num_Matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990495</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977393</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.934253</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.877143</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15022</th>\n",
       "      <td>1992</td>\n",
       "      <td>1273</td>\n",
       "      <td>0.8502</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15023</th>\n",
       "      <td>1992</td>\n",
       "      <td>1609</td>\n",
       "      <td>0.761673</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15024</th>\n",
       "      <td>1992</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.802216</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15025</th>\n",
       "      <td>1992</td>\n",
       "      <td>1991</td>\n",
       "      <td>0.945183</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15026</th>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41528 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reference  Query     Score  Num_Matches\n",
       "0              0      0       1.0           14\n",
       "1              0      1  0.990495           14\n",
       "2              0      2  0.977393           11\n",
       "3              0      3  0.934253           11\n",
       "4              0      4  0.877143           11\n",
       "...          ...    ...       ...          ...\n",
       "15022       1992   1273    0.8502           39\n",
       "15023       1992   1609  0.761673           33\n",
       "15024       1992   1990  0.802216           37\n",
       "15025       1992   1991  0.945183           45\n",
       "15026       1992   1992       1.0           48\n",
       "\n",
       "[41528 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_score = 0.75 # Min score\n",
    "results = pd.DataFrame([], columns=['Reference','Query','Score','Num_Matches'])\n",
    "\n",
    "score_files = sorted(Path(output_dir).glob('*.score.npy'))\n",
    "for score_file in score_files:\n",
    "    batch_idx = int(score_file.stem.split('.')[0])\n",
    "    batch_x_pad = (batch_idx // TOTAL_BATCHES_Y) * BATCH_SIZE\n",
    "    batch_y_pad = (batch_idx % TOTAL_BATCHES_Y) * BATCH_SIZE\n",
    "    \n",
    "    score = np.load(score_file)\n",
    "    \n",
    "    # Condition query\n",
    "    pairs_relative = np.argwhere(score[...,0] >= min_score)\n",
    "    # We have to pad pairs with their actual locations on full grid\n",
    "    pairs_absolute = pairs_relative + [batch_x_pad, batch_y_pad]\n",
    "    \n",
    "    # score, num_matches = get_one_specific(ref_idx, que_idx)\n",
    "    r, q = pairs_relative.T\n",
    "    score, num_match = score[r, q].T\n",
    "    \n",
    "    r, q = pairs_absolute.T\n",
    "    result = pd.DataFrame(dict(\n",
    "        Reference=r.astype('uint32'),\n",
    "        Query=q.astype('uint32'),\n",
    "        Score=score.astype('float32'),\n",
    "        Num_Matches=num_match.astype('uint16')\n",
    "    )).convert_dtypes()\n",
    "    results = pd.concat([results, result], axis=0, copy=False)\n",
    "    \n",
    "print(results.dtypes, \"Memory \", results.memory_usage().sum() / 1e6, 'MB')\n",
    "\n",
    "assert (result.Score >= min_score).all(), \"Something wrong with filtering!\"\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful with how large the `results` dataframe can get! You might run our of RAM before it's all loaded into memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
