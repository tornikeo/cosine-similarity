{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All required imports\n",
    "# import tensorflow as tf\n",
    "# print(\"GPU available\", tf.test.is_gpu_available())\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import numba\n",
    "from typing import Tuple, List\n",
    "from matchms import Spectrum\n",
    "from matchms.typing import SpectrumType\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from numba import cuda\n",
    "from matchms import Spectrum\n",
    "from numba.cuda.cudadrv.devicearray import DeviceNDArray\n",
    "from numba import types\n",
    "from numba.cuda import float32x3\n",
    "import math\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "from matchms.filtering import normalize_intensities\n",
    "from matchms.filtering import require_minimum_number_of_peaks\n",
    "from matchms.filtering import select_by_mz\n",
    "from matchms.filtering import select_by_relative_intensity\n",
    "from matchms.filtering import reduce_to_number_of_peaks\n",
    "from matchms.filtering import add_losses\n",
    "\n",
    "def process_spectrum(spectrum):\n",
    "    spectrum = select_by_mz(spectrum, mz_from=10.0, mz_to=1000.0)\n",
    "    spectrum = normalize_intensities(spectrum)\n",
    "    spectrum = select_by_relative_intensity(spectrum, intensity_from=0.001)\n",
    "    spectrum = reduce_to_number_of_peaks(spectrum, n_max=1000)\n",
    "    spectrum = require_minimum_number_of_peaks(spectrum, n_required=5)\n",
    "    return spectrum\n",
    "\n",
    "\n",
    "def get_ref_spectra_from_df(spectra_df, limit=None):\n",
    "    # This function will take a dataframe with spectra and return a list of matchms spectra\n",
    "    # Argh, This function is annoyingly slow. Added simple parallelization.\n",
    "    \n",
    "    # for index, row in spectra_df.iterrows():\n",
    "    def fn(index, row):\n",
    "        pbid = row[\"pbid\"]\n",
    "        precursor_mz = row[\"precursor_mz\"]\n",
    "        smiles = row[\"pb_smiles\"]\n",
    "        inchikey = row[\"pb_inchikey\"]\n",
    "        mz_array = np.array(json.loads(row[\"peaks_mz\"]))\n",
    "        intensity_array = np.array(json.loads(row[\"peaks_intensities\"]))\n",
    "        sp = Spectrum(mz=mz_array, intensities=intensity_array,\n",
    "                        metadata={'id': pbid, \n",
    "                                'precursor_mz': precursor_mz, \n",
    "                                'smiles': smiles, \n",
    "                                'inchikey': inchikey}) \n",
    "        sp = process_spectrum(sp)\n",
    "        return sp\n",
    "    if limit is not None:\n",
    "        spectra_df = spectra_df.head(limit)\n",
    "    spectra = Parallel(-2)(delayed(fn)(index, row) for index, row in tqdm(spectra_df.iterrows(), total=len(spectra_df)) )\n",
    "    spectra = [s for s in spectra if s is not None]\n",
    "    return spectra\n",
    "\n",
    "def spectra_peaks_to_tensor(spectra: list, fill: float):\n",
    "    sp_max_shape = max(len(s.peaks) for s in spectra)\n",
    "    mz = np.full((len(spectra), sp_max_shape), fill, 'float32')\n",
    "    int = np.full((len(spectra), sp_max_shape), fill, 'float32')\n",
    "    batch = np.zeros(len(spectra),dtype=np.int32)\n",
    "    for i, s in enumerate(spectra):\n",
    "        arr = s.peaks.to_numpy\n",
    "        mz[i, :len(s.peaks)] = arr[...,0] \n",
    "        int[i, :len(s.peaks)] = arr[...,1]\n",
    "        batch[i] = len(s.peaks)\n",
    "    return mz, int, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:04<00:00, 2363.70it/s]\n"
     ]
    }
   ],
   "source": [
    "ref_spectra_df_path = Path(\"data/input/example_dataset_tornike.csv\")\n",
    "ref_spectra_df = pd.read_csv(ref_spectra_df_path)\n",
    "large_references = get_ref_spectra_from_df(ref_spectra_df, limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations: 1048576\n"
     ]
    }
   ],
   "source": [
    "R = 1024\n",
    "Q = 1024\n",
    "references = large_references[Q:Q+R]\n",
    "queries = large_references[:Q]\n",
    "\n",
    "print(f\"Total iterations: {len(queries) * len(references)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "rmz_bs, rint_bs, references_cutoff = spectra_peaks_to_tensor(references, fill=-1e6)\n",
    "qmz_bs, qint_bs, queries_cutoff  = spectra_peaks_to_tensor(queries, fill=-1e6)\n",
    "\n",
    "rmz_cu = cuda.to_device(rmz_bs)\n",
    "rint_cu = cuda.to_device(rint_bs)\n",
    "rlen_cu = cuda.to_device(references_cutoff)\n",
    "\n",
    "qmz_cu = cuda.to_device(qmz_bs)\n",
    "qint_cu = cuda.to_device(qint_bs)\n",
    "qlen_cu = cuda.to_device(queries_cutoff)\n",
    "\n",
    "R,N = rmz_cu.shape\n",
    "Q,M = qmz_cu.shape\n",
    "K = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each SM (streaming multiproc) will take 4.0kb of memory.\n",
      "Upper limit is 64kb of memory per SM.\n",
      "Lowering constant K will result in more SMs to 'Give up' before reaching perfect accuracy (more 1's in overflow)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Each SM (streaming multiproc) will take {(K * 5 * 32 / 8)/1000}kb of memory.\")\n",
    "print(f\"Upper limit is 64kb of memory per SM.\")\n",
    "print(f\"Lowering constant K will result in more SMs to 'Give up' before reaching perfect accuracy (more 1's in overflow)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:05<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6160808.7 per sec\n",
      "6.76hrs per 100k x 1.5mln\n",
      "Correct (excluding overflows): False\n",
      "Correct : False\n",
      "Num matches correct (excluding overflows): False\n",
      "Num matches correct with overflows: False\n",
      "Matches =====\n",
      "% correct (excluding overflows): 99.93%\n",
      "% under (excluding overflows): 0.00%\n",
      "% over (excluding overflows): 0.07%\n",
      "Scores (accounting for fp32 rounding error) =====\n",
      "% correct (excluding overflows): 99.92%\n",
      "% under (excluding overflows): 22.61%\n",
      "% over (excluding overflows): 31.71%\n",
      "Overflows: \n",
      "% overflows : 0.02803802490234375%\n",
      "# overflows : 294\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb#W5sZmlsZQ%3D%3D?line=196'>197</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m% overflows : \u001b[39m\u001b[39m{\u001b[39;00moverflow\u001b[39m.\u001b[39mmean() \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb#W5sZmlsZQ%3D%3D?line=197'>198</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m# overflows : \u001b[39m\u001b[39m{\u001b[39;00moverflow\u001b[39m.\u001b[39msum()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb#W5sZmlsZQ%3D%3D?line=199'>200</a>\u001b[0m \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "@cuda.jit\n",
    "def process(rmz: DeviceNDArray, \n",
    "            qmz: DeviceNDArray,\n",
    "            rint: DeviceNDArray,\n",
    "            qint: DeviceNDArray,\n",
    "            \n",
    "            rlen: DeviceNDArray, \n",
    "            qlen: DeviceNDArray,            \n",
    "            \n",
    "            out: DeviceNDArray,\n",
    "            overflow: DeviceNDArray,\n",
    "            \n",
    "            R: int, \n",
    "            Q: int,\n",
    "            \n",
    "            tolerance: float,\n",
    "            shift: float,\n",
    "            mz_power: float,\n",
    "            int_power: float,\n",
    "            ):\n",
    "    \n",
    "    i,j = cuda.grid(2)\n",
    "    # i = cuda.blockIdx.x\n",
    "    # j = cuda.blockIdx.y\n",
    "    thread_i = cuda.threadIdx.x\n",
    "    thread_j = cuda.threadIdx.y\n",
    "    block_size_x = cuda.blockDim.x\n",
    "    block_size_y = cuda.blockDim.y\n",
    "    match_cap = K\n",
    "    \n",
    "    # mem = cuda.shared.array((8, ))\n",
    "    \n",
    "    # We aren't out of the RxQ grid\n",
    "    if i < R and j < Q:\n",
    "        # In this i,j, We get length of r and q spectrums \n",
    "        # since they are batched, there might be extra filler elements\n",
    "        rleni = rlen[i]\n",
    "        qlenj = qlen[j]\n",
    "        \n",
    "        # shared = cuda.shared.array((10, N), types.float32)\n",
    "        # if thread_i < 5 and thread_j < 5:\n",
    "            \n",
    "        # else:\n",
    "        spec2_mz = qmz[j]\n",
    "        spec2_int = qint[j]\n",
    "        \n",
    "        spec1_mz = rmz[i]\n",
    "        spec1_int = rint[i]\n",
    "            \n",
    "            \n",
    "        # if len(spec2_mz) < 10:\n",
    "        #     spec2_mz_ = qmz[j]\n",
    "        #     spec2_int_ = qint[j]\n",
    "            \n",
    "        #     spec2_mz = cuda.shared.array(M, types.float32)\n",
    "        #     spec2_int = cuda.shared.array(M, types.float32)\n",
    "            \n",
    "        #     for cn in range(qlenj):\n",
    "        #         spec2_mz[cn] = spec2_mz_[cn]\n",
    "        #         spec2_int[cn] = spec2_int_[cn]\n",
    "        \n",
    "        lowest_idx = types.int32(0)\n",
    "        num_match = types.int32(0)\n",
    "        \n",
    "        # For cuda 7.5, each SM (block, basically) has access to \n",
    "        # 64kb mem. This is allocating only (100,5,32) = 2kb\n",
    "        # This can be increased if need be.\n",
    "        matches = cuda.local.array((match_cap,3), types.float32)\n",
    "        \n",
    "        for peak1_idx in range(rleni):\n",
    "            mz = spec1_mz[peak1_idx]\n",
    "            low_bound = mz - tolerance\n",
    "            high_bound = mz + tolerance\n",
    "            \n",
    "            for peak2_idx in range(lowest_idx, qlenj):\n",
    "                mz2 = spec2_mz[peak2_idx] + shift\n",
    "                if mz2 > high_bound:\n",
    "                    break\n",
    "                if mz2 < low_bound:\n",
    "                    lowest_idx = peak2_idx\n",
    "                else:\n",
    "                    if num_match < match_cap:\n",
    "                        power_prod_spec1 = (spec1_mz[peak1_idx] ** mz_power) * (spec1_int[peak1_idx] ** int_power)\n",
    "                        power_prod_spec2 = (spec2_mz[peak2_idx] ** mz_power) * (spec2_int[peak2_idx] ** int_power)\n",
    "                        prod = power_prod_spec1 * power_prod_spec2\n",
    "                        matches[num_match, 0] = prod\n",
    "                        matches[num_match, 1] = peak1_idx\n",
    "                        matches[num_match, 2] = peak2_idx\n",
    "                        num_match += 1\n",
    "                    else:\n",
    "                        overflow[i, j, 0] = 1 # This is the errorcode for overflow\n",
    "                        break\n",
    "\n",
    "        if num_match == 0: \n",
    "            return\n",
    "        \n",
    "        # SLOW, calculate norm ( This should be done in several threads )\n",
    "        # score_norm = types.float32(0.0)\n",
    "        score_norm = types.float32(1.0)\n",
    "        score_norm_spec1 = types.float32(0.0)\n",
    "        score_norm_spec2 = types.float32(0.0)\n",
    "        \n",
    "        for peak1_idx in range(rleni):\n",
    "            score_norm_spec1 += ((spec1_mz[peak1_idx] ** mz_power) * (spec1_int[peak1_idx] ** int_power)) ** 2\n",
    "        for peak2_idx in range(qlenj):\n",
    "            score_norm_spec2 += ((spec2_mz[peak2_idx] ** mz_power) * (spec2_int[peak2_idx] ** int_power)) ** 2\n",
    "        score_norm = math.sqrt(score_norm_spec1 * score_norm_spec2)\n",
    "        \n",
    "        # Extemely slow - Bubble sort (This should also be done in several threads)\n",
    "        # We need two cases, bubble sort up to 50 elems is fine\n",
    "        score = types.float32(0.0)\n",
    "        used_matches = types.int32(0)\n",
    "        # if num_match < 30:\n",
    "        for _ in range(0, num_match):\n",
    "            max_prod = -1\n",
    "            max_peak1_idx = -1\n",
    "            max_peak2_idx = -1\n",
    "            \n",
    "            for sj in range(0, num_match):\n",
    "                if matches[sj,0] > max_prod:\n",
    "                    max_prod = matches[sj,0]\n",
    "                    max_peak1_idx = matches[sj, 1]\n",
    "                    max_peak2_idx = matches[sj, 2]\n",
    "\n",
    "            if max_prod > 0:\n",
    "                for sj in range(0, num_match):\n",
    "                    if matches[sj, 1] == max_peak1_idx or matches[sj, 2] == max_peak2_idx:\n",
    "                        matches[sj, 0] = -2 # \"Remove\" it\n",
    "                score += max_prod\n",
    "                used_matches += 1\n",
    "                \n",
    "            if max_prod < 0:\n",
    "                break\n",
    "            \n",
    "        if score_norm > 0:\n",
    "            score = score / score_norm\n",
    "            \n",
    "        out[i,j,0] = score\n",
    "        out[i,j,1] = used_matches\n",
    "\n",
    "TPB = (32, 32)\n",
    "# Each block has to service single pair of R, Q\n",
    "BPG_x = math.ceil(rmz_cu.shape[0] / TPB[0])\n",
    "BPG_y = math.ceil(qmz_cu.shape[0] / TPB[1])\n",
    "BPG = (BPG_x, BPG_y)\n",
    "\n",
    "tolerance = types.float32(0.1)\n",
    "shift = types.float32(0.0)\n",
    "mz_power = types.float32(0.0)\n",
    "int_power = types.float32(1.0)\n",
    "\n",
    "iters = 30\n",
    "out = np.full((R, Q, 3), fill_value=-1, dtype='float32')\n",
    "overflow = np.full((R, Q, 1), fill_value=0, dtype='uint8')\n",
    "out_cu = cuda.to_device(out)\n",
    "overflow_cu = cuda.to_device(overflow)\n",
    "duration = time.time()\n",
    "for _ in tqdm(range(iters)):\n",
    "    process[BPG, TPB](\n",
    "                    rmz_cu, qmz_cu, \n",
    "                    rint_cu, qint_cu, \n",
    "                    rlen_cu, qlen_cu,\n",
    "                    out_cu, overflow_cu,\n",
    "                    R, Q,\n",
    "                    tolerance, shift, mz_power, int_power)\n",
    "    cuda.synchronize()\n",
    "persec = iters * (R * Q) / (time.time() - duration)\n",
    "out_cu.copy_to_host(out)\n",
    "overflow_cu.copy_to_host(overflow)\n",
    "print(f\"{persec:.1f} per sec\")\n",
    "print(f\"{(100_000 * 1_500_000 / persec) / 3600:.2f}hrs per 100k x 1.5mln\")\n",
    "\n",
    "non_overflow = (1-overflow)\n",
    "out_underflow = out * non_overflow\n",
    "\n",
    "out_true = np.load('data/grid_outp.npy')\n",
    "out_true_underflow = out_true * non_overflow\n",
    "\n",
    "print(\"Correct (excluding overflows):\", np.allclose(out_underflow, out_true_underflow))\n",
    "print(\"Correct :\", np.allclose(out, out_true))\n",
    "\n",
    "print(f\"Num matches correct (excluding overflows):\", np.allclose(out_underflow[...,1], out_true_underflow[...,1]))\n",
    "print(f\"Num matches correct with overflows:\", np.allclose(out[...,1], out_true[...,1]))\n",
    "\n",
    "print(\"Matches =====\")\n",
    "print(f\"% correct (excluding overflows): {(out_underflow[...,1] == out_true_underflow[...,1]).mean() * 100:.2f}%\")\n",
    "print(f\"% under (excluding overflows): {(out_underflow[...,1] < out_true_underflow[...,1]).mean() * 100:.2f}%\")\n",
    "print(f\"% over (excluding overflows): {(out_underflow[...,1] > out_true_underflow[...,1]).mean() * 100:.2f}%\")\n",
    "\n",
    "\n",
    "print(\"Scores (accounting for fp32 rounding error) =====\")\n",
    "print(f\"% correct (excluding overflows): {np.isclose(out_underflow[...,0], out_true_underflow[...,0]).mean() * 100:.2f}%\")\n",
    "print(f\"% under (excluding overflows): {(out_underflow[...,0] < out_true_underflow[...,0]).mean() * 100:.2f}%\")\n",
    "print(f\"% over (excluding overflows): {(out_underflow[...,0] > out_true_underflow[...,0]).mean() * 100:.2f}%\")\n",
    "\n",
    "print(\"Overflows: \")\n",
    "print(f\"% overflows : {overflow.mean() * 100}%\")\n",
    "print(f\"# overflows : {overflow.sum()}\")\n",
    "\n",
    "raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
