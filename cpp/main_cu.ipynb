{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import numba\n",
    "from typing import Tuple, List\n",
    "from matchms import Spectrum\n",
    "from matchms.typing import SpectrumType\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from numba import cuda\n",
    "from matchms import Spectrum\n",
    "from numba.cuda.cudadrv.devicearray import DeviceNDArray\n",
    "from numba import types\n",
    "import math\n",
    "import warnings\n",
    "from numba.core.errors import NumbaPerformanceWarning\n",
    "import time\n",
    "from time import perf_counter\n",
    "from itertools import product\n",
    "\n",
    "# Ignore NumbaPerformanceWarning\n",
    "warnings.simplefilter(\"ignore\", category=NumbaPerformanceWarning)\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "from matchms.filtering import normalize_intensities\n",
    "from matchms.filtering import require_minimum_number_of_peaks\n",
    "from matchms.filtering import select_by_mz\n",
    "from matchms.filtering import select_by_relative_intensity\n",
    "from matchms.filtering import reduce_to_number_of_peaks\n",
    "from matchms.filtering import add_losses\n",
    "\n",
    "def process_spectrum(spectrum):\n",
    "    spectrum = select_by_mz(spectrum, mz_from=10.0, mz_to=1000.0)\n",
    "    spectrum = normalize_intensities(spectrum)\n",
    "    spectrum = select_by_relative_intensity(spectrum, intensity_from=0.001)\n",
    "    spectrum = reduce_to_number_of_peaks(spectrum, n_max=1000)\n",
    "    spectrum = require_minimum_number_of_peaks(spectrum, n_required=5)\n",
    "    return spectrum\n",
    "\n",
    "\n",
    "def get_ref_spectra_from_df(spectra_df, limit=None):\n",
    "    # This function will take a dataframe with spectra and return a list of matchms spectra\n",
    "    # Argh, This function is annoyingly slow. Added simple parallelization.\n",
    "    \n",
    "    # for index, row in spectra_df.iterrows():\n",
    "    def fn(index, row):\n",
    "        pbid = row[\"pbid\"]\n",
    "        precursor_mz = row[\"precursor_mz\"]\n",
    "        smiles = row[\"pb_smiles\"]\n",
    "        inchikey = row[\"pb_inchikey\"]\n",
    "        mz_array = np.array(json.loads(row[\"peaks_mz\"]))\n",
    "        intensity_array = np.array(json.loads(row[\"peaks_intensities\"]))\n",
    "        sp = Spectrum(mz=mz_array, intensities=intensity_array,\n",
    "                        metadata={'id': pbid, \n",
    "                                'precursor_mz': precursor_mz, \n",
    "                                'smiles': smiles, \n",
    "                                'inchikey': inchikey}) \n",
    "        sp = process_spectrum(sp)\n",
    "        return sp\n",
    "    if limit is not None:\n",
    "        spectra_df = spectra_df.head(limit)\n",
    "    spectra = Parallel(-2)(delayed(fn)(index, row) for index, row in tqdm(spectra_df.iterrows(), total=len(spectra_df)) )\n",
    "    spectra = [s for s in spectra if s is not None]\n",
    "    return spectra\n",
    "\n",
    "def spectra_peaks_to_tensor(spectra: list, dtype:str='float32'):\n",
    "    sp_max_shape = max(len(s.peaks) for s in spectra)\n",
    "    mz = np.empty((len(spectra), sp_max_shape), dtype=dtype)\n",
    "    int = np.empty((len(spectra), sp_max_shape), dtype=dtype)\n",
    "    batch = np.empty(len(spectra),dtype=np.int32)\n",
    "    for i, s in enumerate(spectra):\n",
    "        # .to_numpy creates an unneeded copy - we don't need it\n",
    "        # arr = s.peaks\n",
    "        mz[i, :len(s.peaks)] = s._peaks.mz#arr[...,0] \n",
    "        int[i, :len(s.peaks)] = s._peaks.intensities#arr[...,1]\n",
    "        batch[i] = len(s.peaks)\n",
    "    spec = np.stack([mz, int], axis=0)\n",
    "    return spec, batch\n",
    "\n",
    "def batches(lst, batch_size):\n",
    "    for i in range(0, len(lst), batch_size):\n",
    "        yield lst[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0    b'NVIDIA GeForce RTX 2070 with Max-Q Design'                              [SUPPORTED]\n",
      "                      Compute Capability: 7.5\n",
      "                           PCI Device ID: 0\n",
      "                              PCI Bus ID: 1\n",
      "                                    UUID: GPU-f6e241c8-f0ad-720e-be22-2713a6b0868d\n",
      "                                Watchdog: Enabled\n",
      "             FP32/FP64 Performance Ratio: 32\n",
      "Summary:\n",
      "\t1/1 devices are supported\n"
     ]
    }
   ],
   "source": [
    "assert cuda.detect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [00:04<00:00, 2611.62it/s]\n"
     ]
    }
   ],
   "source": [
    "ref_spectra_df_path = Path(\"data/input/example_dataset_tornike.csv\")\n",
    "ref_spectra_df = pd.read_csv(ref_spectra_df_path)\n",
    "large_references = get_ref_spectra_from_df(ref_spectra_df, limit=12_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define constants\n",
    "tolerance: float = 0.1\n",
    "shift: float = 0\n",
    "mz_power: float = 0\n",
    "int_power: float = 1\n",
    "\n",
    "## How many pairs\n",
    "R = 1024\n",
    "Q = 1024\n",
    "# We know absolute max spectrum size we can have...\n",
    "MN = max(len(s.peaks) for s in large_references)\n",
    "\n",
    "## GPU-specific constants\n",
    "# Threads per block (max is 32,32)\n",
    "# Blocks per grid (enough to cover all Rs and Qs)\n",
    "THREADS_PER_BLOCK = (32, 32)\n",
    "BLOCKS_PER_GRID_X = math.ceil(R / THREADS_PER_BLOCK[0])\n",
    "BLOCKS_PER_GRID_Y = math.ceil(Q / THREADS_PER_BLOCK[1])\n",
    "BLOCKS_PER_GRID = (BLOCKS_PER_GRID_X, BLOCKS_PER_GRID_Y)\n",
    "\n",
    "# 'float32' runs MUCH faster, and has around ~0.05% error rate\n",
    "# 'float64' is slower, but has ~0.00095% error rate\n",
    "# Greedy cosine is unstable, so it's virtually impossible to have 0% error rate\n",
    "dtype = 'float64'\n",
    "\n",
    "# Smaller match limit increases speed dramatically!\n",
    "# But any value less than M * N will cause a tiny portion of \n",
    "# pairs to \"overflow\" and have tiny error in calculation.\n",
    "# It is much more efficient to calculate these overflows \n",
    "# separately rather than to increase MATCH_LIMIT.\n",
    "MATCH_LIMIT = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def process(\n",
    "            rspec: DeviceNDArray,\n",
    "            qspec: DeviceNDArray,\n",
    "            \n",
    "            lens: DeviceNDArray,          \n",
    "            \n",
    "            out: DeviceNDArray,\n",
    "            overflow: DeviceNDArray,\n",
    "            ):\n",
    "    i,j = cuda.grid(2)\n",
    "    thread_i = cuda.threadIdx.x\n",
    "    thread_j = cuda.threadIdx.y\n",
    "    block_size_x = cuda.blockDim.x\n",
    "    block_size_y = cuda.blockDim.y\n",
    "    \n",
    "    # mem = cuda.shared.array((8, ))\n",
    "    # We aren't out of the RxQ grid\n",
    "    if i < R and j < Q:\n",
    "        # Init values (we expect these to be uninitialized)\n",
    "        overflow[i,j] = 0\n",
    "        out[i,j] = 0\n",
    "        \n",
    "        # mem = cuda.shared.array((4, 4, 4, 32), types.float32)\n",
    "        rmz = rspec[0]\n",
    "        rint = rspec[1]\n",
    "        qmz = qspec[0]\n",
    "        qint = qspec[1]\n",
    "        # In this i,j, We get length of r and q spectrums \n",
    "        # since they are batched, there might be extra filler elements\n",
    "        rlen = lens[0]\n",
    "        qlen = lens[1]\n",
    "        \n",
    "        rleni = rlen[i]\n",
    "        qlenj = qlen[j]\n",
    "        \n",
    "        spec1_mz = rmz[i]\n",
    "        spec1_int = rint[i]\n",
    "        \n",
    "        spec2_mz = qmz[j]\n",
    "        spec2_int = qint[j]\n",
    "        \n",
    "        lowest_idx = types.int32(0)\n",
    "        num_match = types.int32(0)\n",
    "        \n",
    "        matches = cuda.local.array((2, MATCH_LIMIT), types.int16)\n",
    "        for peak1_idx in range(rleni):\n",
    "            mz = spec1_mz[peak1_idx]\n",
    "\n",
    "            low_bound = mz - tolerance\n",
    "            high_bound = mz + tolerance\n",
    "            \n",
    "            for peak2_idx in range(lowest_idx, qlenj):\n",
    "                mz2 = spec2_mz[peak2_idx] + shift\n",
    "                if mz2 > high_bound:\n",
    "                    break\n",
    "                if mz2 < low_bound:\n",
    "                    lowest_idx = peak2_idx\n",
    "                else:\n",
    "                    if num_match < MATCH_LIMIT:\n",
    "                        matches[0, num_match] = peak1_idx\n",
    "                        matches[1, num_match] = peak2_idx\n",
    "                        num_match += 1\n",
    "                    else:\n",
    "                        overflow[i, j, 0] = 1 # This is the errorcode for overflow\n",
    "                        break\n",
    "\n",
    "        if num_match == 0: \n",
    "            return\n",
    "        \n",
    "        # SLOW, calculate norm ( This should be done in several threads )\n",
    "        # score_norm = types.float32(0.0)\n",
    "        score_norm = types.float32(1.0)\n",
    "        score_norm_spec1 = types.float32(0.0)\n",
    "        score_norm_spec2 = types.float32(0.0)\n",
    "        \n",
    "        for peak1_idx in range(rleni):\n",
    "            score_norm_spec1 += ((spec1_mz[peak1_idx] ** mz_power) * (spec1_int[peak1_idx] ** int_power)) ** 2\n",
    "        for peak2_idx in range(qlenj):\n",
    "            score_norm_spec2 += ((spec2_mz[peak2_idx] ** mz_power) * (spec2_int[peak2_idx] ** int_power)) ** 2\n",
    "        score_norm = math.sqrt(score_norm_spec1 * score_norm_spec2)\n",
    "        \n",
    "        # Quite slow - Bubble sort (This should also be done in several threads)\n",
    "        # We need two cases, bubble sort up to 50 elems is fine\n",
    "        score = types.float32(0.0)\n",
    "        used_matches = types.int32(0)\n",
    "        for _ in range(0, num_match):\n",
    "            max_prod = types.float64(-1.0)\n",
    "            max_peak1_idx = -1\n",
    "            max_peak2_idx = -1\n",
    "            \n",
    "            for sj in range(0, num_match):\n",
    "                if matches[0, sj] >= 0:\n",
    "                    peak1_idx = matches[0, sj]\n",
    "                    peak2_idx = matches[1, sj]\n",
    "                    \n",
    "                    power_prod_spec1 = (spec1_mz[peak1_idx] ** mz_power) * (spec1_int[peak1_idx] ** int_power)\n",
    "                    power_prod_spec2 = (spec2_mz[peak2_idx] ** mz_power) * (spec2_int[peak2_idx] ** int_power)\n",
    "                    prod = power_prod_spec1 * power_prod_spec2\n",
    "                    if prod > max_prod:\n",
    "                        max_prod = prod\n",
    "                        max_peak1_idx = peak1_idx\n",
    "                        max_peak2_idx = peak2_idx\n",
    "\n",
    "            if max_prod > 0:\n",
    "                for sj in range(0, num_match):\n",
    "                    if matches[0, sj] == max_peak1_idx or matches[1, sj] == max_peak2_idx:\n",
    "                        matches[0, sj] = -1 # \"Remove\" it\n",
    "                        matches[1, sj] = -1 # \"Remove\" it\n",
    "                score += max_prod\n",
    "                used_matches += 1\n",
    "                \n",
    "            if max_prod < 0:\n",
    "                break\n",
    "            \n",
    "        score = score / score_norm\n",
    "            \n",
    "        out[i,j,0] = score\n",
    "        out[i,j,1] = used_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular CPU-bound run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs to compare: 1024 * 1024 = 1048576\n"
     ]
    }
   ],
   "source": [
    "references = large_references[:R]\n",
    "queries = large_references[:Q]\n",
    "\n",
    "print(f\"Total pairs to compare: {len(references)} * {len(queries)} = {len(queries) * len(references)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1048576/1048576 [00:12<00:00, 83106.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to collect matching pairs: 12.6753830909729\n",
      "Speed at 82725.4 pairs/sec\n",
      "Estimated 503.67hrs per 100k x 1.5mln\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "@numba.njit\n",
    "def find_matches(spec1_mz: np.ndarray, spec2_mz: np.ndarray,\n",
    "                 tolerance: float, shift: float = 0) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Faster search for matching peaks.\n",
    "    Makes use of the fact that spec1 and spec2 contain ordered peak m/z (from\n",
    "    low to high m/z).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spec1_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    spec2_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance appart.\n",
    "    shift\n",
    "        Shift peaks of second spectra by shift. The default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matches\n",
    "        List containing entries of type (idx1, idx2).\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    lowest_idx = 0\n",
    "    matches = []\n",
    "    for peak1_idx in range(spec1_mz.shape[0]):\n",
    "        mz = spec1_mz[peak1_idx]\n",
    "        low_bound = mz - tolerance\n",
    "        high_bound = mz + tolerance\n",
    "        for peak2_idx in range(lowest_idx, spec2_mz.shape[0]):\n",
    "            mz2 = spec2_mz[peak2_idx] + shift\n",
    "            if mz2 > high_bound:\n",
    "                break\n",
    "            if mz2 < low_bound:\n",
    "                lowest_idx = peak2_idx\n",
    "            else:\n",
    "                matches.append((peak1_idx, peak2_idx))\n",
    "                # print((peak1_idx, peak2_idx))\n",
    "    # print(matches)\n",
    "    return matches\n",
    "\n",
    "\n",
    "@numba.njit(fastmath=True)\n",
    "def score_best_matches(matching_pairs: np.ndarray, spec1: np.ndarray,\n",
    "                       spec2: np.ndarray, mz_power: float = 0.0,\n",
    "                       intensity_power: float = 1.0) -> Tuple[float, int]:\n",
    "    \"\"\"Calculate cosine-like score by multiplying matches. Does require a sorted\n",
    "    list of matching peaks (sorted by intensity product).\"\"\"\n",
    "    score = float(0.0)\n",
    "    used_matches = int(0)\n",
    "    used1 = set()\n",
    "    used2 = set()\n",
    "    for i in range(matching_pairs.shape[0]):\n",
    "        if not matching_pairs[i, 0] in used1 and not matching_pairs[i, 1] in used2:\n",
    "            score += matching_pairs[i, 2]\n",
    "            used1.add(matching_pairs[i, 0])  # Every peak can only be paired once\n",
    "            used2.add(matching_pairs[i, 1])  # Every peak can only be paired once\n",
    "            # print(i, matching_pairs[i,0], matching_pairs[i,1], used_matches, score)\n",
    "            used_matches += 1\n",
    "\n",
    "    # Normalize score:\n",
    "    spec1_power = spec1[:, 0] ** mz_power * spec1[:, 1] ** intensity_power    \n",
    "    spec2_power = spec2[:, 0] ** mz_power * spec2[:, 1] ** intensity_power\n",
    "\n",
    "    # print(spec1_power)\n",
    "    # print(spec2_power)\n",
    "    # raise\n",
    "    score_norm = (np.sum(spec1_power ** 2) ** 0.5 * np.sum(spec2_power ** 2) ** 0.5)\n",
    "    # print(score, score_norm, used_matches)\n",
    "    score = score/score_norm\n",
    "    # print(score, \"/\", score_norm)\n",
    "    # raise\n",
    "    return score, used_matches\n",
    "\n",
    "@numba.njit\n",
    "def collect_peak_pairs(spec1: np.ndarray, spec2: np.ndarray,\n",
    "                       tolerance: float, shift: float = 0, mz_power: float = 0.0,\n",
    "                       intensity_power: float = 1.0):\n",
    "    # pylint: disable=too-many-arguments\n",
    "    \"\"\"Find matching pairs between two spectra.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    spec1:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    spec2:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance appart.\n",
    "    shift\n",
    "        Shift spectra peaks by shift. The default is 0.\n",
    "    mz_power:\n",
    "        The power to raise mz to in the cosine function. The default is 0, in which\n",
    "        case the peak intensity products will not depend on the m/z ratios.\n",
    "    intensity_power:\n",
    "        The power to raise intensity to in the cosine function. The default is 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matching_pairs : numpy array\n",
    "        Array of found matching peaks.\n",
    "    \"\"\"\n",
    "    matches = find_matches(spec1[:, 0], spec2[:, 0], tolerance, shift)\n",
    "    # global a\n",
    "    # a = matches\n",
    "    # matches_op = find_matches_opt(spec1[:, 0], spec2[:, 0], tolerance, shift)\n",
    "    # global b\n",
    "    # b = matches_op\n",
    "    # assert np.allclose(matches, matches_op)\n",
    "    \n",
    "    idx1 = [x[0] for x in matches]\n",
    "    idx2 = [x[1] for x in matches]\n",
    "    if len(idx1) == 0:\n",
    "        return None\n",
    "    matching_pairs = []\n",
    "    for i, idx in enumerate(idx1):\n",
    "        power_prod_spec1 = (spec1[idx, 0] ** mz_power) * (spec1[idx, 1] ** intensity_power)\n",
    "        power_prod_spec2 = (spec2[idx2[i], 0] ** mz_power) * (spec2[idx2[i], 1] ** intensity_power)\n",
    "        # print((idx, idx2[i], power_prod_spec1 * power_prod_spec2))\n",
    "        matching_pairs.append([idx, idx2[i], power_prod_spec1 * power_prod_spec2])\n",
    "    return np.array(matching_pairs.copy())\n",
    "\n",
    "\n",
    "start_collect_peaks = time.time()\n",
    "pairs_to_score_list = []\n",
    "scores = []\n",
    "\n",
    "# We use this array to compare results from CPU to results from GPU\n",
    "out_true = np.full((len(references), len(queries), 2), fill_value=0, dtype='float32')\n",
    "spec1s = []\n",
    "for i,spectrum_1 in enumerate(references):\n",
    "    spec1s.append([i, spectrum_1.peaks.to_numpy])\n",
    "spec2s = []\n",
    "for j,spectrum_2 in enumerate(queries):\n",
    "    spec2s.append([j, spectrum_2.peaks.to_numpy])\n",
    "    \n",
    "total=len(spec1s) * len(spec2s)\n",
    "for (i, spec1), (j, spec2) in tqdm( product(spec1s, spec2s), total=total):\n",
    "        matching_pairs = collect_peak_pairs(\n",
    "                    spec1, \n",
    "                    spec2, \n",
    "                    tolerance=tolerance,\n",
    "                    shift=shift, \n",
    "                    mz_power=mz_power,\n",
    "                    intensity_power=int_power,\n",
    "        )\n",
    "        if matching_pairs is not None:\n",
    "            matching_pairs = matching_pairs[np.argsort(matching_pairs[:, 2])[::-1], :] \n",
    "            score = score_best_matches(matching_pairs, spec1, spec2, \n",
    "                                       mz_power, int_power)\n",
    "            scores.append(score)\n",
    "            out_true[i,j,0] = score[0]\n",
    "            out_true[i,j,1] = score[1]\n",
    "\n",
    "duration = time.time() - start_collect_peaks\n",
    "print(\"Time to collect matching pairs:\", duration)\n",
    "persec = total / duration\n",
    "print(f\"Speed at {persec:.1f} pairs/sec\")\n",
    "print(f\"Estimated {(100_000 * 1_500_000 / persec) / 3600:.2f}hrs per 100k x 1.5mln\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU-based solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rspec: (2, 1024, 211) float64 Qspec (2, 1024, 211) float64\n"
     ]
    }
   ],
   "source": [
    "rspec, references_cutoff = spectra_peaks_to_tensor(references, dtype=dtype)\n",
    "qspec, queries_cutoff  = spectra_peaks_to_tensor(queries, dtype=dtype)\n",
    "\n",
    "rspec_cu = cuda.to_device(rspec)\n",
    "qspec_cu = cuda.to_device(qspec)\n",
    "\n",
    "lens_cu = cuda.to_device(np.stack([references_cutoff, queries_cutoff]))\n",
    "\n",
    "# Batching \n",
    "N = rspec_cu.shape[-1] \n",
    "M = qspec_cu.shape[-1]\n",
    "\n",
    "print(\"Rspec:\", rspec_cu.shape, rspec_cu.dtype, \"Qspec\", qspec_cu.shape, qspec_cu.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run x32, to get avg perf.: 100%|██████████| 32/32 [00:01<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed at 17047389.5/sec\n",
      "Estimated 2.44hrs per 100k x 1.5mln\n",
      "Perfectly correct?: False\n",
      "Except overflows, pefectly correct?: False\n",
      "Total comparisons:  2097152\n",
      "Total correct: 2094206 (99.859524%)\n",
      "Total wrong: 2946 (0.140476%)\n",
      "\t2932 (0.139809%) from overflows; 14 (0.000668%) otherwise\n",
      "Overflows ====\n",
      "Overflows at MATCH_LIMIT=128 : 1488, 0.14191%\n",
      "Matches =====\n",
      "% correct : 99.99943%\n",
      "% under : 0.00038%\n",
      "% over : 0.00019%\n",
      "Scores =====\n",
      "% correct : 99.99924%\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "iters = 32\n",
    "\n",
    "# Init empty (faster) and set values in GPU\n",
    "out = np.empty((R, Q, 2), dtype='float32')\n",
    "overflow = np.empty((R, Q, 1), dtype='uint8')\n",
    "\n",
    "out_cu = cuda.to_device(out)\n",
    "overflow_cu = cuda.to_device(overflow)\n",
    "\n",
    "# Warm up\n",
    "process[(1,1), THREADS_PER_BLOCK](rspec_cu, qspec_cu,\n",
    "                lens_cu,\n",
    "                out_cu, overflow_cu,)\n",
    "\n",
    "perf = perf_counter()\n",
    "# Iterate kernel `iter` times and average performance\n",
    "for _ in tqdm(range(iters), desc=\"Run x32, to get avg perf.\"):\n",
    "    process[BLOCKS_PER_GRID, THREADS_PER_BLOCK](\n",
    "                    rspec_cu, qspec_cu,\n",
    "                    lens_cu,\n",
    "                    out_cu, overflow_cu,\n",
    "                    )\n",
    "    cuda.synchronize()\n",
    "duration = perf_counter() - perf\n",
    "persec = iters * (R * Q) / duration\n",
    "out_cu.copy_to_host(out)\n",
    "overflow_cu.copy_to_host(overflow)\n",
    "\n",
    "print(f\"Speed at {persec:.1f}/sec\")\n",
    "print(f\"Estimated {(100_000 * 1_500_000 / persec) / 3600:.2f}hrs per 100k x 1.5mln\")\n",
    "\n",
    "non_overflow = (1-overflow)\n",
    "out_underflow = out * non_overflow\n",
    "\n",
    "out_true_underflow = out_true * non_overflow\n",
    "\n",
    "print(\"Perfectly correct?:\", np.allclose(out, out_true))\n",
    "print(\"Except overflows, pefectly correct?:\", np.allclose(out_underflow, out_true_underflow))\n",
    "print(f\"Total comparisons: \", R * Q * 2)\n",
    "tc = np.isclose(out[...,:2], out_true[...,:2])\n",
    "print(f\"Total correct: {(tc).sum()} ({tc.sum() / (R * Q * 2 ) * 100 :.6f}%)\")\n",
    "tc_ov = ((1-tc)*(overflow)).sum()\n",
    "tc_noov = ((1-tc)*(1-overflow)).sum()\n",
    "print(f\"Total wrong: {(1-tc).sum()} ({(1-tc).sum() / (R * Q * 2 ) * 100 :.6f}%)\")\n",
    "print(f\"\\t{tc_ov} ({tc_ov / (R * Q * 2 ) * 100 :.6f}%) from overflows; {tc_noov} ({tc_noov / (R * Q * 2 ) * 100 :.6f}%) otherwise\")\n",
    "\n",
    "print(\"Overflows ====\")\n",
    "print(f\"Overflows at MATCH_LIMIT={MATCH_LIMIT} : {overflow.sum()}, {overflow.mean() * 100:.5f}%\")\n",
    "\n",
    "print(\"Matches =====\")\n",
    "print(f\"% correct : {np.isclose(out_underflow[...,1], out_true_underflow[...,1]).mean() * 100:.5f}%\")\n",
    "print(f\"% under : {(out_underflow[...,1] < out_true_underflow[...,1]).mean() * 100:.5f}%\")\n",
    "print(f\"% over : {(out_underflow[...,1] > out_true_underflow[...,1]).mean() * 100:.5f}%\")\n",
    "\n",
    "print(\"Scores =====\")\n",
    "print(f\"% correct : {np.isclose(out_underflow[...,0], out_true_underflow[...,0]).mean() * 100:.5f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the two results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = out_true\n",
    "gpu = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1024, 2) (1024, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "print(cpu.shape, gpu.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Get normed similarity and num_matches for R no. 42 and Q no. 77."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim from CPU:  0.0  And from GPU 0.0\n",
      "Score of 0 means the we didn't find any matches. So, matches should be 0. Let's check!\n"
     ]
    }
   ],
   "source": [
    "print(\"Sim from CPU: \", cpu[42, 77, 0], \" And from GPU\", gpu[42, 77, 0])\n",
    "print(\"Score of 0 means the we didn't find any matches. So, matches should be 0. Let's check!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get num matches for R no. 42 and Q no. 77."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim from CPU:  0.0  And from GPU 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Sim from CPU: \", cpu[42, 77, 1], \" And from GPU\", gpu[42, 77, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some other scores that aren't zero. `cpu[32,32]` will show `[<similarity>, <num matches>]` when we print it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: [ 0.457 13.   ]\n",
      "GPU: [ 0.457 13.   ]\n"
     ]
    }
   ],
   "source": [
    "print('CPU:',cpu[32, 32])\n",
    "print('GPU:',gpu[32, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when GPU overflows! This doesn't ever happen in CPU.\n",
    "We keep track of overflows in array called `overflow`. If `overflow[i,j] == 1`, an overflow happened while comparing R[i] and Q[i]. However, score should still be reasonably close in CPU/GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overflow shape (1024, 1024, 1)\n",
      "Small sample of overflow...\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "If you see any 1's, you are pretty lucky! We have only 0.02% overflows\n"
     ]
    }
   ],
   "source": [
    "print(\"Overflow shape\", overflow.shape)\n",
    "print(\"Small sample of overflow...\")\n",
    "print(overflow[:16,:32].squeeze())\n",
    "print(\"If you see any 1's, you are pretty lucky! We have only 0.02% overflows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's any first overflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_ov = gpu[(overflow == 1).squeeze()]\n",
    "cpu_ov = cpu[(overflow == 1).squeeze()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see them side-by-side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overflows only!\n",
      "GPU score, GPU count, CPU score, CPU count\n",
      "[[9.02827e-02 5.50000e+01 1.02779e-01 6.00000e+01]\n",
      " [5.03936e-01 6.40000e+01 5.03944e-01 6.40000e+01]\n",
      " [8.95316e-02 5.90000e+01 8.95345e-02 6.00000e+01]\n",
      " [9.81815e-02 5.20000e+01 1.03995e-01 5.90000e+01]\n",
      " [5.62814e-01 6.20000e+01 5.62818e-01 6.30000e+01]\n",
      " [1.04077e-01 5.40000e+01 1.06113e-01 5.70000e+01]\n",
      " [1.66156e-01 6.60000e+01 1.66509e-01 6.70000e+01]\n",
      " [3.60311e-01 5.90000e+01 3.66729e-01 7.00000e+01]\n",
      " [4.42532e-01 6.00000e+01 4.43200e-01 6.50000e+01]\n",
      " [4.86722e-02 6.80000e+01 4.87097e-02 7.10000e+01]\n",
      " [4.12475e-02 6.80000e+01 4.12758e-02 7.00000e+01]\n",
      " [3.38245e-02 6.50000e+01 3.40067e-02 6.70000e+01]\n",
      " [1.60929e-01 6.40000e+01 1.65542e-01 7.40000e+01]\n",
      " [3.33284e-01 5.90000e+01 3.78094e-01 7.80000e+01]\n",
      " [4.49645e-01 5.80000e+01 4.85082e-01 7.60000e+01]\n",
      " [4.52101e-01 5.80000e+01 4.72201e-01 7.30000e+01]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=5)\n",
    "print(\"Overflows only!\")\n",
    "print(\"GPU score, GPU count, CPU score, CPU count\")\n",
    "print(np.c_[gpu_ov[:16], cpu_ov[:16]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full run (batched GPU solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches:  9\n",
      "Total pairs considered: 11776 * 11776 = 138674176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:13<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed at 10569625.3 pairs/sec\n",
      "Estimated 3.94hrs per 100k x 1.5mln\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# How many batches do we have?\n",
    "\n",
    "# Full run\n",
    "references = large_references\n",
    "queries = large_references\n",
    "\n",
    "TOTAL_BATCHES = math.ceil( len(references) / R ) * math.ceil( len(queries) / Q)\n",
    "print(\"Total batches: \", TOTAL_BATCHES)\n",
    "print(f\"Total pairs considered: {len(references)} * {len(queries)} = {len(references) * len(queries)}\")\n",
    "\n",
    "stream_outputs = [np.empty((R, Q, 2), dtype='float32') for _ in range(TOTAL_BATCHES)]\n",
    "stream_overflows = [np.empty((R, Q, 1), dtype='uint8') for _ in range(TOTAL_BATCHES)]\n",
    "streams = [cuda.stream() for _ in range(TOTAL_BATCHES)]\n",
    "\n",
    "batches_r = list(batches(references, R))\n",
    "batches_q = list(batches(queries, Q))\n",
    "\n",
    "out_cu = cuda.device_array((R, Q, 2), dtype='float32')\n",
    "overflow_cu = cuda.device_array((R, Q, 1), dtype='uint8')\n",
    "start = perf_counter()\n",
    "for batch_i, (rbatch, qbatch) in tqdm(enumerate(product(batches_r, batches_q)), total=TOTAL_BATCHES):\n",
    "    stream = streams[batch_i]\n",
    "    \n",
    "    out = np.empty((TOTAL_BATCHES, R, Q, 2), dtype='float32')\n",
    "    overflow = np.empty((TOTAL_BATCHES, R, Q, 1), dtype='uint8')\n",
    "    rspec, rlen = spectra_peaks_to_tensor(rbatch, dtype=dtype)\n",
    "    qspec, qlen  = spectra_peaks_to_tensor(qbatch, dtype=dtype)\n",
    "    \n",
    "    lens = np.zeros((2, max(R, Q)), 'int32')\n",
    "    lens[0,:len(rlen)] = rlen\n",
    "    lens[1,:len(qlen)] = qlen\n",
    "\n",
    "    with cuda.pinned(rspec, qspec, lens, out, overflow,):\n",
    "        rspec_cu = cuda.to_device(rspec, stream=stream)\n",
    "        qspec_cu = cuda.to_device(qspec, stream=stream)\n",
    "        lens_cu = cuda.to_device(lens, stream=stream)\n",
    "        \n",
    "        process[BLOCKS_PER_GRID, THREADS_PER_BLOCK, stream](\n",
    "                rspec_cu, qspec_cu,\n",
    "                lens_cu,\n",
    "                out_cu, overflow_cu,\n",
    "        )\n",
    "        out_cu.copy_to_host(stream_outputs[batch_i], stream=stream)\n",
    "        overflow_cu.copy_to_host(stream_overflows[batch_i], stream=stream)\n",
    "        \n",
    "cuda.synchronize()\n",
    "duration = perf_counter() - start\n",
    "persec = len(references) * len(queries) / duration\n",
    "print(f\"Speed at {persec:.1f} pairs/sec\")\n",
    "print(f\"Estimated {(100_000 * 1_500_000 / persec) / 3600:.2f}hrs per 100k x 1.5mln\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1048576/1048576 [00:43<00:00, 24063.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# for batch_i, (rbatch, qbatch) in enumerate(product(batches_r, batches_q)):\n",
    "#     out_true = np.empty((len(rbatch), len(qbatch), 2), dtype='float32')\n",
    "#     for (i, spec1), (j, spec2) in tqdm( product( enumerate(rbatch), enumerate(qbatch)), total=R * Q):\n",
    "#         spec1 = spec1.peaks.to_numpy\n",
    "#         spec2 = spec2.peaks.to_numpy\n",
    "#         matching_pairs = collect_peak_pairs(\n",
    "#             spec1,\n",
    "#             spec2,\n",
    "#             tolerance=tolerance,\n",
    "#             shift=shift, \n",
    "#             mz_power=mz_power,\n",
    "#             intensity_power=int_power,\n",
    "#         )\n",
    "#         if matching_pairs is not None:\n",
    "#             matching_pairs = matching_pairs[np.argsort(matching_pairs[:, 2])[::-1], :] \n",
    "#             score = score_best_matches(matching_pairs, spec1, spec2, \n",
    "#                                     mz_power, int_power)\n",
    "#             scores.append(score)\n",
    "#             out_true[i,j,0] = score[0]\n",
    "#             out_true[i,j,1] = score[1]\n",
    "#         else:\n",
    "#             out_true[i,j,0] = 0\n",
    "#             out_true[i,j,1] = 0\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rbatch), len(qbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfectly correct?: False\n",
      "Except overflows, pefectly correct?: False\n",
      "Total comparisons:  2097152\n",
      "Total correct: 2096748 (99.980736%)\n",
      "Total wrong: 404 (0.019264%)\n",
      "\t398 (0.018978%) from overflows; 6 (0.000286%) otherwise\n",
      "Overflows ====\n",
      "Overflows at MATCH_LIMIT=128 : 203, 0.01936%\n",
      "Matches =====\n",
      "% correct : 99.99971%\n",
      "% under : 0.00010%\n",
      "% over : 0.00019%\n",
      "Scores =====\n",
      "% correct : 99.99971%\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(out,overflow, out_true):\n",
    "    non_overflow = (1-overflow)\n",
    "    out_underflow = out * non_overflow\n",
    "\n",
    "    out_true_underflow = out_true * non_overflow\n",
    "\n",
    "    print(\"Perfectly correct?:\", np.allclose(out, out_true))\n",
    "    print(\"Except overflows, pefectly correct?:\", np.allclose(out_underflow, out_true_underflow))\n",
    "    print(f\"Total comparisons: \", R * Q * 2)\n",
    "    tc = np.isclose(out[...,:2], out_true[...,:2])\n",
    "    print(f\"Total correct: {(tc).sum()} ({tc.sum() / (R * Q * 2 ) * 100 :.6f}%)\")\n",
    "    tc_ov = ((1-tc)*(overflow)).sum()\n",
    "    tc_noov = ((1-tc)*(1-overflow)).sum()\n",
    "    print(f\"Total wrong: {(1-tc).sum()} ({(1-tc).sum() / (R * Q * 2 ) * 100 :.6f}%)\")\n",
    "    print(f\"\\t{tc_ov} ({tc_ov / (R * Q * 2 ) * 100 :.6f}%) from overflows; {tc_noov} ({tc_noov / (R * Q * 2 ) * 100 :.6f}%) otherwise\")\n",
    "\n",
    "    print(\"Overflows ====\")\n",
    "    print(f\"Overflows at MATCH_LIMIT={MATCH_LIMIT} : {overflow.sum()}, {overflow.mean() * 100:.5f}%\")\n",
    "\n",
    "    print(\"Matches =====\")\n",
    "    print(f\"% correct : {np.isclose(out_underflow[...,1], out_true_underflow[...,1]).mean() * 100:.5f}%\")\n",
    "    print(f\"% under : {(out_underflow[...,1] < out_true_underflow[...,1]).mean() * 100:.5f}%\")\n",
    "    print(f\"% over : {(out_underflow[...,1] > out_true_underflow[...,1]).mean() * 100:.5f}%\")\n",
    "\n",
    "    print(\"Scores =====\")\n",
    "    print(f\"% correct : {np.isclose(out_underflow[...,0], out_true_underflow[...,0]).mean() * 100:.5f}%\")\n",
    "    \n",
    "check_accuracy(\n",
    "    out = stream_outputs[0],\n",
    "    overflow = stream_overflows[0],\n",
    "    out_true = out_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 7/64 [00:00<00:04, 12.36it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb Cell 33\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb#X60sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     rspec, references_cutoff \u001b[39m=\u001b[39m spectra_peaks_to_tensor(rbatch, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb#X60sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     qspec, queries_cutoff  \u001b[39m=\u001b[39m spectra_peaks_to_tensor(qbatch, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb#X60sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     lens \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mstack([references_cutoff, queries_cutoff])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb#X60sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# for batch_i, rbatch in tqdm(enumerate(), total=len(references)//R):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb#X60sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m#     for batch_j, qbatch in enumerate(batches(queries, Q)):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb#X60sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m#         out = np.empty((TOTAL_BATCHES, R, Q, 2), dtype='float32')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb#X60sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m#             out_cu.copy_to_host(out, stream=stream)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb#X60sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m#             overflow_cu.copy_to_host(overflow, stream=stream)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pb2/lib/python3.10/site-packages/numpy/core/shape_base.py:449\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    447\u001b[0m shapes \u001b[39m=\u001b[39m {arr\u001b[39m.\u001b[39mshape \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays}\n\u001b[1;32m    448\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shapes) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 449\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mall input arrays must have the same shape\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    451\u001b[0m result_ndim \u001b[39m=\u001b[39m arrays[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mndim \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    452\u001b[0m axis \u001b[39m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "# # with cuda.defer_cleanup():\n",
    "# # rspec_cu = cuda.device_array((2, R, MN), dtype=np.float64, stream=stream) # mz+int, R, MN\n",
    "# # qspec_cu = cuda.device_array((2, Q, MN), dtype=np.float64, stream=stream) # mz+int, Q, MN\n",
    "# # lens_cu = cuda.device_array((2, R, Q )) # Rlen+Qlen, R\n",
    "# from itertools import product\n",
    "\n",
    "# def spectra_peaks_to_tensor(spectra: list, prealloc:list[np.ndarray] = None, dtype:str='float32'):\n",
    "#     sp_max_shape = max(len(s.peaks) for s in spectra)\n",
    "#     if prealloc is None:\n",
    "#         spec = np.empty((2, len(spectra), sp_max_shape), dtype=dtype)\n",
    "#         batch = np.empty(len(spectra),dtype=np.int32)\n",
    "#     else:\n",
    "#         spec, batch = prealloc\n",
    "#     for i, s in enumerate(spectra):\n",
    "#         spec[0, i, :len(s.peaks)] = s._peaks.mz\n",
    "#         spec[1, i, :len(s.peaks)] = s._peaks.intensities\n",
    "#         batch[i] = len(s.peaks)\n",
    "#     return spec, batch\n",
    "\n",
    "# stream_outputs = np.empty((TOTAL_BATCHES, R, Q, 2), dtype='float32')\n",
    "# streams = [cuda.stream() for _ in range(TOTAL_BATCHES)]\n",
    "# batches_r = batches(references, R)\n",
    "# batches_q = batches(queries, Q)\n",
    "# pairs_batches = product(batches_r, batches_q)\n",
    "\n",
    "# rspec = np.empty((2, R, MN), dtype=np.float64)\n",
    "# qspec = np.empty((2, Q, MN), dtype=np.float64)\n",
    "# lens = np.empty((2, max(R, N)), dtype=np.int32)\n",
    "\n",
    "# for batch_i, (rbatch, qbatch) in tqdm(enumerate(pairs_batches), total=TOTAL_BATCHES):\n",
    "#     stream = streams[batch_i]\n",
    "    \n",
    "#     rspec, rlen = spectra_peaks_to_tensor(rbatch, prealloc=[rspec, ] dtype=dtype)\n",
    "#     qspec, qlen  = spectra_peaks_to_tensor(qbatch, dtype=dtype)\n",
    "#     lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from time import perf_counter, sleep\n",
    "\n",
    "# N_streams = 10\n",
    "# with cuda.defer_cleanup():\n",
    "#     streams = [cuda.stream() for _ in range(1, N_streams + 1)]\n",
    "\n",
    "#     tics = []  # Launch start times\n",
    "#     for i, (stream, arr) in enumerate(zip(streams, arrays)):\n",
    "#         tic = perf_counter()\n",
    "#         with cuda.pinned(arr):\n",
    "#             dev_a = cuda.to_device(arr, stream=stream)\n",
    "#             dev_a_reduce = cuda.device_array(\n",
    "#                 (blocks_per_grid,), dtype=dev_a.dtype, stream=stream\n",
    "#             )\n",
    "#             dev_a_sum = cuda.device_array((1,), dtype=dev_a.dtype, stream=stream)\n",
    "            \n",
    "#             dev_a.copy_to_host(arr, stream=stream)\n",
    "\n",
    "#         toc = perf_counter()  # Stop time of launches\n",
    "#         print(f\"Launched processing {i} in {1e3 * (toc - tic):.2f} ms\")\n",
    "\n",
    "#         # Ensure that the reference to the GPU arrays are deleted, this will\n",
    "#         # ensure garbage collection at the exit of the context.\n",
    "#         del dev_a, dev_a_reduce, dev_a_sum\n",
    "\n",
    "#         tics.append(tic)\n",
    "\n",
    "#     tocs = []\n",
    "#     for i, (stream, arr) in enumerate(zip(streams, arrays)):\n",
    "#         stream.synchronize()\n",
    "#         toc = perf_counter()  # Stop time of sync\n",
    "#         tocs.append(toc)\n",
    "#         print(f\"New sum (array {i}): {arr.sum():12.2f}\")\n",
    "#     for i in range(4):\n",
    "#         print(f\"Performed processing {i} in {1e3 * (tocs[i] - tics[i]):.2f} ms\")\n",
    "\n",
    "#     print(f\"Total time {1e3 * (tocs[-1] - tics[0]):.2f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
