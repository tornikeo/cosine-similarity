{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All required imports\n",
    "# import tensorflow as tf\n",
    "# print(\"GPU available\", tf.test.is_gpu_available())\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import numba\n",
    "from typing import Tuple, List\n",
    "from matchms import Spectrum\n",
    "from matchms.typing import SpectrumType\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from matchms import Spectrum\n",
    "\n",
    "from matchms.filtering import normalize_intensities\n",
    "from matchms.filtering import require_minimum_number_of_peaks\n",
    "from matchms.filtering import select_by_mz\n",
    "from matchms.filtering import select_by_relative_intensity\n",
    "from matchms.filtering import reduce_to_number_of_peaks\n",
    "from matchms.filtering import add_losses\n",
    "\n",
    "def process_spectrum(spectrum):\n",
    "    spectrum = select_by_mz(spectrum, mz_from=10.0, mz_to=1000.0)\n",
    "    spectrum = normalize_intensities(spectrum)\n",
    "    spectrum = select_by_relative_intensity(spectrum, intensity_from=0.001)\n",
    "    spectrum = reduce_to_number_of_peaks(spectrum, n_max=1000)\n",
    "    spectrum = require_minimum_number_of_peaks(spectrum, n_required=5)\n",
    "    return spectrum\n",
    "\n",
    "\n",
    "def get_ref_spectra_from_df(spectra_df, limit=None):\n",
    "    # This function will take a dataframe with spectra and return a list of matchms spectra\n",
    "    # Argh, This function is annoyingly slow. Added simple parallelization.\n",
    "    \n",
    "    # for index, row in spectra_df.iterrows():\n",
    "    def fn(index, row):\n",
    "        pbid = row[\"pbid\"]\n",
    "        precursor_mz = row[\"precursor_mz\"]\n",
    "        smiles = row[\"pb_smiles\"]\n",
    "        inchikey = row[\"pb_inchikey\"]\n",
    "        mz_array = np.array(json.loads(row[\"peaks_mz\"]))\n",
    "        intensity_array = np.array(json.loads(row[\"peaks_intensities\"]))\n",
    "        sp = Spectrum(mz=mz_array, intensities=intensity_array,\n",
    "                        metadata={'id': pbid, \n",
    "                                'precursor_mz': precursor_mz, \n",
    "                                'smiles': smiles, \n",
    "                                'inchikey': inchikey}) \n",
    "        sp = process_spectrum(sp)\n",
    "        return sp\n",
    "    if limit is not None:\n",
    "        spectra_df = spectra_df.head(limit)\n",
    "    spectra = Parallel(-2)(delayed(fn)(index, row) for index, row in tqdm(spectra_df.iterrows(), total=len(spectra_df)) )\n",
    "    spectra = [s for s in spectra if s is not None]\n",
    "    return spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:08<00:00, 1229.28it/s]\n"
     ]
    }
   ],
   "source": [
    "ref_spectra_df_path = Path(\"data/input/example_dataset_tornike.csv\")\n",
    "ref_spectra_df = pd.read_csv(ref_spectra_df_path)\n",
    "large_references = get_ref_spectra_from_df(ref_spectra_df, limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations: 50\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "M = 5\n",
    "queries = large_references[:N]\n",
    "references = large_references[N:N+M]\n",
    "\n",
    "print(f\"Total iterations: {len(queries) * len(references)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectra_peaks_to_tensor(spectra: list, fill: float):\n",
    "    sp_max_shape = max(len(s.peaks) for s in spectra)\n",
    "    mz = np.full((len(spectra), sp_max_shape), fill, 'float32')\n",
    "    int = np.full((len(spectra), sp_max_shape), fill, 'float32')\n",
    "    batch = np.zeros(len(spectra),dtype=np.int32)\n",
    "    for i, s in enumerate(spectra):\n",
    "        arr = s.peaks.to_numpy\n",
    "        mz[i, :len(s.peaks)] = arr[...,0] \n",
    "        int[i, :len(s.peaks)] = arr[...,1]\n",
    "        batch[i] = len(s.peaks)\n",
    "    return mz, int, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tornikeo/miniconda3/envs/pb2/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 50 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct without overflows: False\n",
      "Correct with overflows: False\n",
      "[[ 5.  6.  8.  8. 13. 22. 33. 43. 52. 61.]\n",
      " [ 5.  6.  8.  8. 13. 21. 32. 41. 49. 59.]\n",
      " [12. 12. 12. 13. 13. 13. 11. 11. 10.  9.]\n",
      " [ 3.  4.  4.  5.  4.  4.  3.  3.  3.  3.]\n",
      " [ 3.  4.  4.  5.  4.  4.  3.  3.  3.  3.]]\n",
      "[[0.059 0.077 0.102 0.175 0.143 0.187 0.301 0.481 0.648 0.801]\n",
      " [0.031 0.049 0.064 0.122 0.073 0.093 0.17  0.309 0.475 0.675]\n",
      " [0.995 0.996 0.995 0.963 0.914 0.852 0.73  0.489 0.267 0.146]\n",
      " [0.692 0.705 0.736 0.605 0.374 0.302 0.995 0.993 0.993 0.994]\n",
      " [0.597 0.627 0.747 0.812 0.673 0.615 0.994 0.99  0.991 0.992]]\n",
      "[[ 5.  6.  8.  8. 13. 22. 33. 43. 52. 62.]\n",
      " [ 5.  6.  8.  8. 13. 21. 32. 41. 49. 59.]\n",
      " [12. 12. 12. 13. 13. 13. 11. 11. 10.  9.]\n",
      " [ 3.  4.  4.  5.  4.  4.  3.  3.  3.  3.]\n",
      " [ 3.  4.  4.  5.  4.  4.  3.  3.  3.  3.]]\n",
      "[[0.026 0.034 0.065 0.112 0.162 0.238 0.385 0.566 0.743 0.916]\n",
      " [0.006 0.009 0.022 0.042 0.067 0.112 0.209 0.355 0.541 0.766]\n",
      " [0.984 0.997 0.996 0.964 0.915 0.853 0.704 0.461 0.232 0.104]\n",
      " [0.325 0.326 0.277 0.197 0.147 0.15  0.188 0.221 0.217 0.174]\n",
      " [0.28  0.29  0.282 0.264 0.264 0.306 0.393 0.461 0.453 0.363]]\n"
     ]
    }
   ],
   "source": [
    "from numba.cuda.cudadrv.devicearray import DeviceNDArray\n",
    "from numba import types\n",
    "from numba.cuda import float32x3\n",
    "import math\n",
    "\n",
    "rmz_bs, rint_bs, references_cutoff = spectra_peaks_to_tensor(references, fill=-1e6)\n",
    "qmz_bs, qint_bs, queries_cutoff  = spectra_peaks_to_tensor(queries, fill=-1e6)\n",
    "\n",
    "rmz_cu = cuda.to_device(rmz_bs)\n",
    "rint_cu = cuda.to_device(rint_bs)\n",
    "rlen_cu = cuda.to_device(references_cutoff)\n",
    "\n",
    "qmz_cu = cuda.to_device(qmz_bs)\n",
    "qint_cu = cuda.to_device(qint_bs)\n",
    "qlen_cu = cuda.to_device(queries_cutoff)\n",
    "\n",
    "R,N = rmz_cu.shape\n",
    "Q,M = qmz_cu.shape\n",
    "\n",
    "K = 100\n",
    "\n",
    "out = np.full((R, Q, 3), fill_value=-1, dtype='float32')\n",
    "overflow = np.full((R, Q, 1), fill_value=0, dtype='uint8')\n",
    "out_cu = cuda.to_device(out)\n",
    "overflow_cu = cuda.to_device(overflow)        \n",
    "\n",
    "@cuda.jit\n",
    "def process(rmz: DeviceNDArray, \n",
    "            qmz: DeviceNDArray,\n",
    "            rint: DeviceNDArray,\n",
    "            qint: DeviceNDArray,\n",
    "            rlen: DeviceNDArray, \n",
    "            qlen: DeviceNDArray,            \n",
    "            out: DeviceNDArray,\n",
    "            overflow: DeviceNDArray,\n",
    "            \n",
    "            R: int, \n",
    "            Q: int,\n",
    "            M: int,\n",
    "            N: int,\n",
    "            \n",
    "            tolerance: float,\n",
    "            shift: float,\n",
    "            mz_power: float,\n",
    "            int_power: float,\n",
    "            ):\n",
    "    \n",
    "    i,j = cuda.grid(2)\n",
    "    thread_i = cuda.threadIdx.x\n",
    "    thread_j = cuda.threadIdx.y\n",
    "    match_cap = 100\n",
    "    \n",
    "    # Using shared `matches` array like we do, \n",
    "    # requires guaranteeing exclusive access for 0-thread\n",
    "    if thread_i == 0 and thread_j == 0:\n",
    "        \n",
    "        if i < R and j < Q:\n",
    "            \n",
    "            spec1_mz = rmz[i]\n",
    "            spec2_mz = qmz[j]\n",
    "            \n",
    "            spec1_int = rint[i]\n",
    "            spec2_int = qint[j]\n",
    "            \n",
    "            lowest_idx = types.int32(0)\n",
    "            num_match = types.int32(0)\n",
    "            # For cuda 7.5, each SM (block, basically) has access to \n",
    "            # 64kb mem. This is allocating only (100,5,32) = 2kb\n",
    "            # This can be increased if need be.\n",
    "            matches = cuda.shared.array((match_cap,5), types.float32)\n",
    "                    \n",
    "            for peak1_idx in range(rlen[i]):\n",
    "                mz = spec1_mz[peak1_idx]\n",
    "                low_bound = mz - tolerance\n",
    "                high_bound = mz + tolerance\n",
    "                \n",
    "                for peak2_idx in range(lowest_idx, qlen[j]):\n",
    "                    mz2 = spec2_mz[peak2_idx] + shift\n",
    "                    if mz2 > high_bound:\n",
    "                        break\n",
    "                    if mz2 < low_bound:\n",
    "                        lowest_idx = peak2_idx\n",
    "                    else:\n",
    "                        if num_match < match_cap:\n",
    "                            power_prod_spec1 = (spec1_mz[peak1_idx] ** mz_power) * (spec1_int[peak1_idx] ** int_power)\n",
    "                            power_prod_spec2 = (spec2_mz[peak2_idx] ** mz_power) * (spec2_int[peak2_idx] ** int_power)\n",
    "                            prod = power_prod_spec1 * power_prod_spec2\n",
    "                            matches[num_match, 0] = prod\n",
    "                            matches[num_match, 1] = peak1_idx\n",
    "                            matches[num_match, 2] = peak2_idx\n",
    "                            matches[num_match, 3] = power_prod_spec1\n",
    "                            matches[num_match, 4] = power_prod_spec2\n",
    "                            num_match += 1\n",
    "                        else:\n",
    "                            overflow[i, j, 0] = 1 # This is the errorcode for overflow\n",
    "                            break\n",
    "\n",
    "            if num_match == 0: \n",
    "                return\n",
    "            \n",
    "            # Extemely slow - Bubble sort\n",
    "            \n",
    "            score = types.float32(0.0)\n",
    "            score_norm_spec1 = types.float32(0.0)\n",
    "            score_norm_spec2 = types.float32(0.0)\n",
    "            used_matches = types.int32(0)\n",
    "            # We need two cases, bubble sort up to 50 elems is fine\n",
    "            # if num_match < 50:\n",
    "            for si in range(0, num_match):\n",
    "                score_norm_spec1 += matches[si, 3] ** 2\n",
    "                score_norm_spec2 += matches[si, 4] ** 2\n",
    "                \n",
    "            for si in range(0, num_match):\n",
    "                max_prod = -1\n",
    "                max_peak1_idx = -1\n",
    "                max_peak2_idx = -1\n",
    "                \n",
    "                for sj in range(0, num_match):\n",
    "                    if matches[sj,0] > max_prod:\n",
    "                        max_prod = matches[sj,0]\n",
    "                        max_peak1_idx = matches[sj, 1]\n",
    "                        max_peak2_idx = matches[sj, 2]\n",
    "\n",
    "                if max_prod > 0:\n",
    "                    for sj in range(0, num_match):\n",
    "                        if matches[sj, 1] == max_peak1_idx or matches[sj, 2] == max_peak2_idx:\n",
    "                            matches[sj, 0] = -1 # \"Remove\" it\n",
    "                    score += max_prod\n",
    "                    used_matches += 1\n",
    "                    \n",
    "                if max_prod < 0:\n",
    "                    break\n",
    "                \n",
    "            if score > 0:\n",
    "                score = score / math.sqrt(score_norm_spec1 * score_norm_spec2)\n",
    "                \n",
    "            out[i,j,0] = score\n",
    "            out[i,j,1] = used_matches\n",
    "\n",
    "TPB = (1,1)\n",
    "BPG_x = math.ceil(rmz_cu.shape[0] / TPB[0])\n",
    "BPG_y = math.ceil(qmz_cu.shape[0] / TPB[0])\n",
    "BPG = (BPG_x, BPG_y)\n",
    "\n",
    "tolerance = types.float32(0.1)\n",
    "shift = types.float32(0.0)\n",
    "mz_power = types.float32(0.0)\n",
    "int_power = types.float32(1.0)\n",
    "\n",
    "process[BPG, TPB](\n",
    "                rmz_cu, qmz_cu, \n",
    "                rint_cu, qint_cu, \n",
    "                rlen_cu, qlen_cu,\n",
    "                out_cu, overflow_cu,\n",
    "                \n",
    "                R, Q, M, N,\n",
    "                \n",
    "                tolerance, shift, mz_power, int_power)\n",
    "out_cu.copy_to_host(out)\n",
    "overflow_cu.copy_to_host(overflow)\n",
    "\n",
    "non_overflow = (1-overflow)\n",
    "out_underflow = out * non_overflow\n",
    "\n",
    "out_true = np.load('data/grid_outp.npy')\n",
    "out_true_underflow = out_true * non_overflow\n",
    "\n",
    "print(\"Correct without overflows:\", np.allclose(out_underflow, out_true_underflow))\n",
    "print(\"Correct with overflows:\", np.allclose(out, out_true))\n",
    "\n",
    "print(out[...,1])\n",
    "print(out[...,0])\n",
    "print(out_true[...,1])\n",
    "print(out_true[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.367e-02,  6.977e-02,  1.287e-01,  2.249e-01,  3.377e-01,\n",
       "         5.318e-01,  1.058e+00,  1.420e+00,  1.898e+00,  0.000e+00],\n",
       "       [ 1.020e-02,  1.600e-02,  3.745e-02,  7.308e-02,  1.206e-01,\n",
       "         2.159e-01,  4.978e-01,  7.696e-01,  1.194e+00,  2.112e+00],\n",
       "       [ 1.103e+00,  1.100e+00,  1.081e+00,  1.053e+00,  1.035e+00,\n",
       "         1.035e+00,  1.053e+00,  6.292e-01,  3.221e-01,  1.812e-01],\n",
       "       [ 3.667e-01,  3.612e-01,  3.029e-01,  2.162e-01,  1.668e-01,\n",
       "         1.833e-01,  2.829e-01,  3.031e-01,  3.031e-01,  3.030e-01],\n",
       "       [ 3.801e-01,  3.864e-01,  3.699e-01,  3.492e-01,  3.612e-01,\n",
       "         4.492e-01,  7.117e-01,  7.622e-01,  7.622e-01,  7.621e-01],\n",
       "       [ 1.936e-01,  2.130e-01,  2.648e-01,  3.489e-01,  4.415e-01,\n",
       "         5.833e-01,  9.349e-01,  1.001e+00,  1.001e+00,  1.001e+00],\n",
       "       [ 7.344e-02,  9.733e-02,  1.779e-01,  3.057e-01,  4.284e-01,\n",
       "         5.805e-01,  9.345e-01,  1.000e+00,  1.001e+00,  1.001e+00],\n",
       "       [ 3.832e-02,  6.351e-02,  1.525e-01,  2.931e-01,  4.245e-01,\n",
       "         5.796e-01,  9.344e-01,  1.000e+00,  1.001e+00,  1.001e+00],\n",
       "       [ 3.336e-02,  5.873e-02,  1.489e-01,  2.913e-01,  4.240e-01,\n",
       "         5.795e-01,  9.345e-01,  1.001e+00,  1.001e+00,  1.002e+00],\n",
       "       [ 3.294e-02,  5.832e-02,  1.486e-01,  2.912e-01,  4.240e-01,\n",
       "         5.796e-01,  9.350e-01,  1.002e+00,  1.005e+00,  1.011e+00],\n",
       "       [ 3.210e-02,  5.752e-02,  1.480e-01,  2.909e-01,  4.239e-01,\n",
       "         5.798e-01,  9.366e-01,  1.008e+00,  1.023e+00,  1.058e+00],\n",
       "       [ 3.149e-02,  5.692e-02,  1.476e-01,  2.907e-01,  4.239e-01,\n",
       "         5.806e-01,  9.418e-01,  1.028e+00,  1.085e+00,  1.221e+00],\n",
       "       [ 3.126e-02,  5.671e-02,  1.475e-01,  2.907e-01,  4.240e-01,\n",
       "         5.824e-01,  9.564e-01,  1.085e+00,  1.263e+00,  1.699e+00],\n",
       "       [ 1.086e-02,  2.020e-02,  5.359e-02,  1.063e-01,  1.553e-01,\n",
       "         2.151e-01,  3.646e-01,  4.535e-01,  6.394e-01,  1.095e+00],\n",
       "       [ 3.405e-03,  6.387e-03,  1.703e-02,  3.382e-02,  4.944e-02,\n",
       "         7.026e-02,  1.295e-01,  1.980e-01,  3.725e-01,  7.984e-01],\n",
       "       [ 1.042e-03,  1.963e-03,  5.232e-03,  1.039e-02,  1.519e-02,\n",
       "         2.340e-02,  5.256e-02,  1.118e-01,  2.744e-01,  6.706e-01],\n",
       "       [ 2.452e-04,  4.662e-04,  1.241e-03,  2.468e-03,  3.607e-03,\n",
       "         7.304e-03,  2.429e-02,  7.415e-02,  2.156e-01,  5.631e-01],\n",
       "       [-1.000e+00, -1.000e+00, -1.000e+00, -1.000e+00, -1.000e+00,\n",
       "         1.399e-03,  9.315e-03,  3.839e-02,  1.225e-01,  3.345e-01],\n",
       "       [ 1.000e+00,  1.000e+00,  1.001e+00,  1.001e+00,  1.004e+00,\n",
       "         1.014e+00,  1.041e+00,  6.314e-01,  3.341e-01,  2.042e-01],\n",
       "       [ 1.001e+00,  1.001e+00,  1.001e+00,  1.002e+00,  1.008e+00,\n",
       "         1.027e+00,  1.076e+00,  6.767e-01,  3.818e-01,  2.687e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.367e-02,  6.977e-02,  1.287e-01,  2.249e-01,  3.377e-01,\n",
       "         5.318e-01,  1.058e+00,  1.420e+00,  1.898e+00,  0.000e+00],\n",
       "       [ 1.020e-02,  1.600e-02,  3.745e-02,  7.308e-02,  1.206e-01,\n",
       "         2.159e-01,  4.978e-01,  7.696e-01,  1.194e+00,  2.112e+00],\n",
       "       [ 1.103e+00,  1.100e+00,  1.081e+00,  1.053e+00,  1.035e+00,\n",
       "         1.035e+00,  1.053e+00,  6.292e-01,  3.221e-01,  1.812e-01],\n",
       "       [ 3.667e-01,  3.612e-01,  3.029e-01,  2.162e-01,  1.668e-01,\n",
       "         1.833e-01,  2.829e-01,  3.031e-01,  3.031e-01,  3.030e-01],\n",
       "       [ 3.801e-01,  3.864e-01,  3.699e-01,  3.492e-01,  3.612e-01,\n",
       "         4.492e-01,  7.117e-01,  7.622e-01,  7.622e-01,  7.621e-01],\n",
       "       [ 1.936e-01,  2.130e-01,  2.648e-01,  3.489e-01,  4.415e-01,\n",
       "         5.833e-01,  9.349e-01,  1.001e+00,  1.001e+00,  1.001e+00],\n",
       "       [ 7.344e-02,  9.733e-02,  1.779e-01,  3.057e-01,  4.284e-01,\n",
       "         5.805e-01,  9.345e-01,  1.000e+00,  1.001e+00,  1.001e+00],\n",
       "       [ 3.832e-02,  6.351e-02,  1.525e-01,  2.931e-01,  4.245e-01,\n",
       "         5.796e-01,  9.344e-01,  1.000e+00,  1.001e+00,  1.001e+00],\n",
       "       [ 3.336e-02,  5.873e-02,  1.489e-01,  2.913e-01,  4.240e-01,\n",
       "         5.795e-01,  9.345e-01,  1.001e+00,  1.001e+00,  1.002e+00],\n",
       "       [ 3.294e-02,  5.832e-02,  1.486e-01,  2.912e-01,  4.240e-01,\n",
       "         5.796e-01,  9.350e-01,  1.002e+00,  1.005e+00,  1.011e+00],\n",
       "       [ 3.210e-02,  5.752e-02,  1.480e-01,  2.909e-01,  4.239e-01,\n",
       "         5.798e-01,  9.366e-01,  1.008e+00,  1.023e+00,  1.058e+00],\n",
       "       [ 3.149e-02,  5.692e-02,  1.476e-01,  2.907e-01,  4.239e-01,\n",
       "         5.806e-01,  9.418e-01,  1.028e+00,  1.085e+00,  1.221e+00],\n",
       "       [ 3.126e-02,  5.671e-02,  1.475e-01,  2.907e-01,  4.240e-01,\n",
       "         5.824e-01,  9.564e-01,  1.085e+00,  1.263e+00,  1.699e+00],\n",
       "       [ 1.086e-02,  2.020e-02,  5.359e-02,  1.063e-01,  1.553e-01,\n",
       "         2.151e-01,  3.646e-01,  4.535e-01,  6.394e-01,  1.095e+00],\n",
       "       [ 3.405e-03,  6.387e-03,  1.703e-02,  3.382e-02,  4.944e-02,\n",
       "         7.026e-02,  1.295e-01,  1.980e-01,  3.725e-01,  7.984e-01],\n",
       "       [ 1.042e-03,  1.963e-03,  5.232e-03,  1.039e-02,  1.519e-02,\n",
       "         2.340e-02,  5.256e-02,  1.118e-01,  2.744e-01,  6.706e-01],\n",
       "       [ 2.452e-04,  4.662e-04,  1.241e-03,  2.468e-03,  3.607e-03,\n",
       "         7.304e-03,  2.429e-02,  7.415e-02,  2.156e-01,  5.631e-01],\n",
       "       [-1.000e+00, -1.000e+00, -1.000e+00, -1.000e+00, -1.000e+00,\n",
       "         1.399e-03,  9.315e-03,  3.839e-02,  1.225e-01,  3.345e-01],\n",
       "       [ 1.000e+00,  1.000e+00,  1.001e+00,  1.001e+00,  1.004e+00,\n",
       "         1.014e+00,  1.041e+00,  6.314e-01,  3.341e-01,  2.042e-01],\n",
       "       [ 1.001e+00,  1.001e+00,  1.001e+00,  1.002e+00,  1.008e+00,\n",
       "         1.027e+00,  1.076e+00,  6.767e-01,  3.818e-01,  2.687e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_true_underflow[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 10, 3), (20, 10, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_true.shape, overflow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  6.,  8.,  8., 13., 22., 33., 43., 52.,  0.],\n",
       "       [ 5.,  6.,  8.,  8., 13., 21., 32., 41., 49., 59.],\n",
       "       [12., 12., 12., 13., 13., 13., 11., 11., 10.,  9.],\n",
       "       [ 3.,  4.,  4.,  5.,  4.,  4.,  3.,  3.,  3.,  3.],\n",
       "       [ 3.,  4.,  4.,  5.,  4.,  4.,  3.,  3.,  3.,  3.],\n",
       "       [ 3.,  4.,  4.,  5.,  6.,  7.,  6.,  6.,  6.,  6.],\n",
       "       [ 3.,  4.,  4.,  4.,  6.,  6.,  5.,  5.,  5.,  5.],\n",
       "       [ 2.,  3.,  3.,  3.,  5.,  6.,  5.,  5.,  5.,  5.],\n",
       "       [ 3.,  4.,  4.,  4.,  6.,  7.,  6.,  6.,  6.,  6.],\n",
       "       [ 4.,  5.,  5.,  5.,  7.,  8.,  9.,  9.,  9.,  9.],\n",
       "       [ 4.,  5.,  5.,  5.,  7.,  9., 10., 12., 13., 13.],\n",
       "       [ 4.,  5.,  5.,  5.,  9., 11., 14., 17., 19., 21.],\n",
       "       [ 4.,  5.,  5.,  5., 10., 12., 17., 21., 24., 28.],\n",
       "       [ 3.,  4.,  4.,  4.,  8., 10., 17., 21., 23., 28.],\n",
       "       [ 1.,  2.,  2.,  2.,  3.,  5., 12., 15., 17., 22.],\n",
       "       [ 1.,  2.,  2.,  2.,  3.,  4.,  9., 12., 15., 21.],\n",
       "       [ 1.,  2.,  2.,  2.,  2.,  3.,  8., 11., 14., 19.],\n",
       "       [-1., -1., -1., -1., -1.,  1.,  5.,  8., 11., 16.],\n",
       "       [ 5.,  5.,  6.,  7.,  9., 11., 11., 11., 10.,  9.],\n",
       "       [ 6.,  6.,  7.,  8., 12., 18., 20., 20., 19., 18.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out * non_overflow[...,None])[...,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/tornikeo/miniconda3/envs/pb2/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "100%|██████████| 8/8 [00:00<00:00, 37.77it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "for br in tqdm(range(0, math.ceil(len(references) / batch_size))):\n",
    "    for bq in range(0, math.ceil(len(queries) / batch_size)):\n",
    "        rmz_bs, rint_bs, references_cutoff = spectra_peaks_to_tensor(references[br:br+batch_size], fill=-1e6)\n",
    "        qmz_bs, qint_bs, queries_cutoff  = spectra_peaks_to_tensor(queries[bq:bq+batch_size], fill=-1e6)\n",
    "\n",
    "        \n",
    "        rmz_cu = cuda.to_device(rmz_bs)\n",
    "        rint_cu = cuda.to_device(rint_bs)\n",
    "        rlen_cu = cuda.to_device(references_cutoff)\n",
    "\n",
    "        qmz_cu = cuda.to_device(qmz_bs)\n",
    "        qint_cu = cuda.to_device(qint_bs)\n",
    "        qlen_cu = cuda.to_device(queries_cutoff)\n",
    "\n",
    "        R,N = rmz_cu.shape\n",
    "        Q,M = qmz_cu.shape\n",
    "\n",
    "        K = 100\n",
    "\n",
    "        out = np.full((R, Q, 3), fill_value=-1, dtype='float32')\n",
    "        overflow = np.full((R, Q), fill_value=0, dtype='uint8')\n",
    "        out_cu = cuda.to_device(out)\n",
    "        overflow_cu = cuda.to_device(overflow)        \n",
    "\n",
    "        TPB = (1,1)\n",
    "        BPG_x = math.ceil(rmz_cu.shape[0] / TPB[0])\n",
    "        BPG_y = math.ceil(qmz_cu.shape[0] / TPB[0])\n",
    "        BPG = (BPG_x, BPG_y)\n",
    "\n",
    "        tolerance = types.float32(0.1)\n",
    "        shift = types.float32(0.0)\n",
    "        mz_power = types.float32(0.0)\n",
    "        int_power = types.float32(1.0)\n",
    "\n",
    "        process[BPG, TPB](\n",
    "                        rmz_cu, qmz_cu, \n",
    "                        rint_cu, qint_cu, \n",
    "                        rlen_cu, qlen_cu,\n",
    "                        out_cu, overflow_cu,\n",
    "                        \n",
    "                        R, Q, M, N,\n",
    "                        \n",
    "                        tolerance, shift, mz_power, int_power)\n",
    "        out_cu.copy_to_host(out)\n",
    "        overflow_cu.copy_to_host(overflow)\n",
    "        # print(overflow.sum())\n",
    "        # print(np.allclose(np.load('data/grid_outp.npy'), out, atol=1e-2))\n",
    "        # print(out.shape)\n",
    "        # print(out[...,0,1])\n",
    "        # print(overflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0029296875"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overflow.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(out[..., ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 100, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2582912"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out.nbytes * 32 * 32) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.849462890625"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((out == -1), axis=(2,3)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 77, 96, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.866282496"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod((512, 512, 71, 77, 2)) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.620976231783484, 0, 526, 20.412919474583756)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = out[...,0].ravel().astype('int32')\n",
    "z.mean(), z.min(), z.max(), z.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(np.bincount(z), )\n",
    "# plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 71), (20, 77))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmz_cu.shape, rmz_cu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.180654e+02,  1.250155e+02,  1.320811e+02,  1.330844e+02,\n",
       "         1.435732e+02,  1.440810e+02,  1.445916e+02,  1.450786e+02,\n",
       "         1.450844e+02,  1.540421e+02,  1.550454e+02,  1.680577e+02,\n",
       "         2.851158e+02,  2.861193e+02, -1.000000e+06, -1.000000e+06,\n",
       "        -1.000000e+06, -1.000000e+06, -1.000000e+06, -1.000000e+06,\n",
       "        -1.000000e+06, -1.000000e+06, -1.000000e+06, -1.000000e+06,\n",
       "        -1.000000e+06, -1.000000e+06, -1.000000e+06, -1.000000e+06,\n",
       "        -1.000000e+06, -1.000000e+06, -1.000000e+06, -1.000000e+06,\n",
       "        -1.000000e+06, -1.000000e+06, -1.000000e+06, -1.000000e+06,\n",
       "        -1.000000e+06, -1.000000e+06, -1.000000e+06, -1.000000e+06,\n",
       "        -1.000000e+06, -1.000000e+06, -1.000000e+06, -1.000000e+06,\n",
       "        -1.000000e+06, -1.000000e+06, -1.000000e+06, -1.000000e+06,\n",
       "        -1.000000e+06, -1.000000e+06, -1.000000e+06, -1.000000e+06,\n",
       "        -1.000000e+06, -1.000000e+06, -1.000000e+06, -1.000000e+06,\n",
       "        -1.000000e+06, -1.000000e+06, -1.000000e+06, -1.000000e+06,\n",
       "        -1.000000e+06, -1.000000e+06, -1.000000e+06, -1.000000e+06,\n",
       "        -1.000000e+06, -1.000000e+06, -1.000000e+06, -1.000000e+06,\n",
       "        -1.000000e+06, -1.000000e+06, -1.000000e+06], dtype=float32),\n",
       " (20, 77))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raise\n",
    "qmz_cu[0].copy_to_host(), rmz_cu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DeviceNDArrayBase.copy_to_device() missing 1 required positional argument: 'ary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main_cu.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m qmz_cu[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mcopy_to_device()\n",
      "File \u001b[0;32m~/miniconda3/envs/pb2/lib/python3.10/site-packages/numba/cuda/cudadrv/devices.py:232\u001b[0m, in \u001b[0;36mrequire_context.<locals>._require_cuda_context\u001b[0;34m(*args, **kws)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(fn)\n\u001b[1;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_require_cuda_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkws):\n\u001b[1;32m    231\u001b[0m     \u001b[39mwith\u001b[39;00m _runtime\u001b[39m.\u001b[39mensure_context():\n\u001b[0;32m--> 232\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkws)\n",
      "\u001b[0;31mTypeError\u001b[0m: DeviceNDArrayBase.copy_to_device() missing 1 required positional argument: 'ary'"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def collect_peak_pairs(spec1: np.ndarray, spec2: np.ndarray,\n",
    "                       tolerance: float, shift: float = 0, mz_power: float = 0.0,\n",
    "                       intensity_power: float = 1.0):\n",
    "    # pylint: disable=too-many-arguments\n",
    "    \"\"\"Find matching pairs between two spectra.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    spec1:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    spec2:\n",
    "        Spectrum peaks and intensities as numpy array.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance appart.\n",
    "    shift\n",
    "        Shift spectra peaks by shift. The default is 0.\n",
    "    mz_power:\n",
    "        The power to raise mz to in the cosine function. The default is 0, in which\n",
    "        case the peak intensity products will not depend on the m/z ratios.\n",
    "    intensity_power:\n",
    "        The power to raise intensity to in the cosine function. The default is 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matching_pairs : numpy array\n",
    "        Array of found matching peaks.\n",
    "    \"\"\"\n",
    "    matches = find_matches(spec1[:, 0], spec2[:, 0], tolerance, shift)\n",
    "    # global a\n",
    "    # a = matches\n",
    "    # matches_op = find_matches_opt(spec1[:, 0], spec2[:, 0], tolerance, shift)\n",
    "    # global b\n",
    "    # b = matches_op\n",
    "    # assert np.allclose(matches, matches_op)\n",
    "    \n",
    "    idx1 = [x[0] for x in matches]\n",
    "    idx2 = [x[1] for x in matches]\n",
    "    if len(idx1) == 0:\n",
    "        return None\n",
    "    matching_pairs = []\n",
    "    for i, idx in enumerate(idx1):\n",
    "        power_prod_spec1 = (spec1[idx, 0] ** mz_power) * (spec1[idx, 1] ** intensity_power)\n",
    "        power_prod_spec2 = (spec2[idx2[i], 0] ** mz_power) * (spec2[idx2[i], 1] ** intensity_power)\n",
    "        # print((idx, idx2[i], power_prod_spec1 * power_prod_spec2))\n",
    "        # raise\n",
    "        matching_pairs.append([idx, idx2[i], power_prod_spec1 * power_prod_spec2])\n",
    "    # print(matching_pairs)\n",
    "    # raise\n",
    "    return np.array(matching_pairs.copy())\n",
    "\n",
    "\n",
    "# @numba.njit\n",
    "def find_matches(spec1_mz: np.ndarray, spec2_mz: np.ndarray,\n",
    "                 tolerance: float, shift: float = 0) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Faster search for matching peaks.\n",
    "    Makes use of the fact that spec1 and spec2 contain ordered peak m/z (from\n",
    "    low to high m/z).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spec1_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    spec2_mz:\n",
    "        Spectrum peak m/z values as numpy array. Peak mz values must be ordered.\n",
    "    tolerance\n",
    "        Peaks will be considered a match when <= tolerance appart.\n",
    "    shift\n",
    "        Shift peaks of second spectra by shift. The default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matches\n",
    "        List containing entries of type (idx1, idx2).\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    lowest_idx = 0\n",
    "    matches = []\n",
    "    for peak1_idx in range(spec1_mz.shape[0]):\n",
    "        mz = spec1_mz[peak1_idx]\n",
    "        low_bound = mz - tolerance\n",
    "        high_bound = mz + tolerance\n",
    "        for peak2_idx in range(lowest_idx, spec2_mz.shape[0]):\n",
    "            mz2 = spec2_mz[peak2_idx] + shift\n",
    "            if mz2 > high_bound:\n",
    "                break\n",
    "            if mz2 < low_bound:\n",
    "                lowest_idx = peak2_idx\n",
    "            else:\n",
    "                matches.append((peak1_idx, peak2_idx))\n",
    "                # print((peak1_idx, peak2_idx))\n",
    "    # print(matches)\n",
    "    return matches\n",
    "\n",
    "\n",
    "@numba.njit(fastmath=True)\n",
    "def score_best_matches(matching_pairs: np.ndarray, spec1: np.ndarray,\n",
    "                       spec2: np.ndarray, mz_power: float = 0.0,\n",
    "                       intensity_power: float = 1.0) -> Tuple[float, int]:\n",
    "    \"\"\"Calculate cosine-like score by multiplying matches. Does require a sorted\n",
    "    list of matching peaks (sorted by intensity product).\"\"\"\n",
    "    score = float(0.0)\n",
    "    used_matches = int(0)\n",
    "    used1 = set()\n",
    "    used2 = set()\n",
    "    for i in range(matching_pairs.shape[0]):\n",
    "        if not matching_pairs[i, 0] in used1 and not matching_pairs[i, 1] in used2:\n",
    "            score += matching_pairs[i, 2]\n",
    "            used1.add(matching_pairs[i, 0])  # Every peak can only be paired once\n",
    "            used2.add(matching_pairs[i, 1])  # Every peak can only be paired once\n",
    "            # print(i, matching_pairs[i,0], matching_pairs[i,1], used_matches, score)\n",
    "            used_matches += 1\n",
    "    # print(score)\n",
    "    # raise\n",
    "    # Normalize score:\n",
    "    spec1_power = spec1[:, 0] ** mz_power * spec1[:, 1] ** intensity_power\n",
    "    \n",
    "    spec2_power = spec2[:, 0] ** mz_power * spec2[:, 1] ** intensity_power\n",
    "\n",
    "    # print(spec1_power)\n",
    "    # print(spec2_power)\n",
    "    # raise\n",
    "    score_norm = (np.sum(spec1_power ** 2) ** 0.5 * np.sum(spec2_power ** 2) ** 0.5)\n",
    "    # print(score, score_norm, used_matches)\n",
    "    score = score/score_norm\n",
    "    # print(score, \"/\", score_norm)\n",
    "    # raise\n",
    "    return score, used_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 871.57it/s]\n",
      "100%|██████████| 195/195 [00:00<00:00, 31363.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to collect matching pairs:  0.033110857009887695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_collect_peaks = time.time()\n",
    "pairs_to_score_list = []\n",
    "scores = []\n",
    "grid_outp = np.full((len(references), len(queries), 3), \n",
    "                    fill_value=-1, \n",
    "                    dtype='float32')\n",
    "for i,spectrum_1 in tqdm(enumerate(references)):\n",
    "    for j,spectrum_2 in enumerate(queries):\n",
    "        spec1 = spectrum_1.peaks.to_numpy\n",
    "        spec2 = spectrum_2.peaks.to_numpy\n",
    "        \n",
    "        matching_pairs = collect_peak_pairs(\n",
    "                    spectrum_1.peaks.to_numpy, \n",
    "                    spectrum_2.peaks.to_numpy, \n",
    "                    tolerance=0.1,\n",
    "                    shift=0.0, \n",
    "                    mz_power=0.0,\n",
    "                    intensity_power=1.0\n",
    "        )\n",
    "        if matching_pairs is not None:\n",
    "            # Store in grid\n",
    "            grid_outp[i,j,0] = matching_pairs[0,0]\n",
    "            grid_outp[i,j,1] = matching_pairs[0,1]\n",
    "            grid_outp[i,j,2] = matching_pairs[0,2]\n",
    "            matching_pairs = matching_pairs[np.argsort(matching_pairs[:, 2])[::-1], :] \n",
    "            pairs_to_score_list.append([ matching_pairs, spectrum_1, spectrum_2]) \n",
    "for matching_pairs, spectrum_1, spectrum_2 in tqdm(pairs_to_score_list):\n",
    "    scores.append(score_best_matches(matching_pairs, spectrum_1.peaks.to_numpy, spectrum_2.peaks.to_numpy,\n",
    "                                0.0, 1.0))\n",
    "end_collect_peaks = time.time()\n",
    "print(\"Time to collect matching pairs: \", end_collect_peaks - start_collect_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49. 49. 47. 47. 25. 20.  7.  1.  1.  0.]\n",
      " [54. 54. 52. 52. 30. 26. 10.  1.  1.  0.]\n",
      " [ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 2.  2.  2.  2.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  1.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 2.  2.  2.  2.  1.  0.  0.  0.  0.  0.]\n",
      " [ 2.  2.  2.  2.  1.  0.  0.  0.  0.  0.]\n",
      " [ 5.  5.  5.  5.  4.  0.  0.  0.  0.  0.]\n",
      " [ 8.  8.  8.  8.  7.  3.  3.  0.  0.  0.]\n",
      " [16. 16. 16. 16.  9.  6.  4.  0.  0.  0.]\n",
      " [28. 28. 28. 28. 19. 14.  6.  0.  0.  0.]\n",
      " [30. 30. 30. 30. 20. 15.  7.  1.  1.  0.]\n",
      " [29. 29. 29. 29. 21. 17.  9.  1.  1.  0.]\n",
      " [32. 32. 32. 32. 25. 21. 17.  1.  1.  0.]\n",
      " [33. 33. 33. 33. 33. 24. 18.  1.  1.  0.]\n",
      " [-1. -1. -1. -1. -1. 25. 20.  2.  2.  0.]\n",
      " [ 6.  6.  2.  2.  0.  0.  0.  0.  0.  0.]\n",
      " [ 8.  8.  6.  6.  0.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  2.  5. 14. 22. 29. 37.]\n",
      " [ 1.  1.  2.  2.  7. 10. 20. 28. 36. 44.]\n",
      " [ 1.  1.  2.  2.  7. 10. 20. 28. 36. 44.]\n",
      " [ 1.  1.  2.  2.  6.  0.  2.  7. 10. 15.]\n",
      " [ 1.  1.  2.  2.  6.  9. 19. 27. 35. 43.]\n",
      " [ 1.  1.  2.  2.  6.  0.  2.  7. 10. 15.]\n",
      " [ 1.  1.  2.  2.  6.  0.  2.  7. 10. 15.]\n",
      " [ 1.  1.  2.  2.  6.  0.  2.  7. 10. 15.]\n",
      " [ 1.  1.  2.  2.  6.  0.  2.  1.  1.  4.]\n",
      " [ 1.  1.  2.  2.  0.  0.  1.  1.  1.  4.]\n",
      " [ 1.  1.  2.  2.  0.  0.  0.  0.  0.  1.]\n",
      " [ 1.  1.  2.  2.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  2.  2.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  2.  2.  0.  0.  1.  0.  0.  0.]\n",
      " [ 1.  1.  2.  2.  7.  0.  1.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1.  0.  1.  0.  0.  0.]\n",
      " [ 4.  5.  0.  0.  1.  3. 10. 18. 24. 32.]\n",
      " [ 0.  0.  0.  0.  0.  1.  4.  9. 13. 18.]]\n",
      "[[ 1.01638274e-04  1.00426856e-04  9.03065200e-04  4.71099047e-03\n",
      "   1.04609109e-03  2.31657689e-03  6.45289947e-06  6.62624589e-05\n",
      "   3.90285888e-04  1.26102077e-05]\n",
      " [ 6.29669739e-05  6.22164735e-05  5.74412232e-04  2.99651735e-03\n",
      "   8.00905982e-04  2.60260259e-03  1.96392580e-06  1.14719325e-04\n",
      "   6.75696821e-04  2.77755225e-05]\n",
      " [ 4.44719990e-05  4.39419382e-05  3.78757136e-06  1.97584977e-05\n",
      "   6.94388063e-06  3.09107891e-05  1.29703272e-04  2.85667047e-04\n",
      "   5.20685862e-04  9.02430969e-04]\n",
      " [ 8.80360231e-03  1.64935514e-02  4.39878330e-02  8.73448923e-02\n",
      "   1.27656758e-01  1.74629435e-01  2.81633794e-01  3.01501513e-01\n",
      "   3.01501513e-01  3.01501513e-01]\n",
      " [ 2.22060047e-02  4.16029543e-02  1.10953905e-01  2.20316768e-01\n",
      "   3.21998507e-01  4.40481275e-01  7.10386634e-01  7.60500491e-01\n",
      "   7.60500491e-01  7.60500491e-01]\n",
      " [ 2.91991998e-02  5.47047034e-02  1.45895898e-01  2.89699703e-01\n",
      "   3.52705047e-06  2.86572867e-06  1.81643099e-05  6.84909101e-05\n",
      "   2.07225239e-04  5.23348164e-04]\n",
      " [ 2.91991998e-02  5.47047034e-02  1.45895898e-01  2.89699703e-01\n",
      "   4.00801218e-06  6.01201782e-06  1.02705308e-05  1.15230341e-05\n",
      "   1.20240356e-05  9.76952924e-06]\n",
      " [ 2.91991998e-02  5.47047034e-02  1.45895898e-01  2.89699703e-01\n",
      "   5.29057570e-06  2.60520778e-06  1.65130095e-05  6.22644657e-05\n",
      "   1.88386592e-04  4.75771056e-04]\n",
      " [ 2.91991998e-02  5.47047034e-02  1.45895898e-01  2.89699703e-01\n",
      "   6.09217841e-06  8.07614379e-06  5.11903309e-05  1.93019849e-04\n",
      "   5.83998393e-04  1.47489028e-03]\n",
      " [ 2.91991998e-02  5.47047034e-02  1.45895898e-01  2.89699703e-01\n",
      "   6.73346040e-06  4.71021558e-05  2.98555213e-04  1.12574152e-03\n",
      "   3.40602943e-03  8.60194117e-03]\n",
      " [ 2.91991998e-02  5.47047034e-02  1.45895898e-01  2.89699703e-01\n",
      "   6.89378066e-06  2.34755280e-04  1.48798723e-03  5.41081636e-06\n",
      "   2.16232256e-05  8.54908940e-05]\n",
      " [ 2.91991998e-02  5.47047034e-02  1.45895898e-01  2.89699703e-01\n",
      "   2.40480722e-06  8.28924996e-04  1.04047995e-05  4.62083699e-05\n",
      "   1.84662335e-04  7.30092230e-04]\n",
      " [ 2.91991998e-02  5.47047034e-02  1.45895898e-01  2.89699703e-01\n",
      "   9.15329747e-06  2.48755654e-03  1.82364545e-06  1.30260389e-06\n",
      "   7.67233723e-06  2.82404526e-05]\n",
      " [ 1.06926356e-02  2.00326554e-02  5.34265228e-02  1.06086925e-01\n",
      "   9.75449893e-06  2.60260259e-03  2.10420626e-06  5.70139719e-06\n",
      "   3.35812292e-05  3.75751119e-06]\n",
      " [ 3.40452720e-03  6.37838244e-03  1.70109645e-02  3.37780006e-02\n",
      "   6.16231864e-06  2.60260259e-03  1.40280417e-06  1.74148117e-05\n",
      "   1.02573242e-04  1.17084055e-05]\n",
      " [ 1.04228570e-03  1.95272244e-03  5.20785572e-03  1.03410324e-02\n",
      "   2.70540818e-06  2.60260259e-03  7.92715655e-05  3.59318292e-05\n",
      "   2.11638471e-04  3.09318311e-05]\n",
      " [ 2.45226518e-04  4.59431903e-04  1.22529187e-03  2.43301340e-03\n",
      "   3.55591043e-03  2.36941036e-03  6.49649664e-05  8.09818812e-05\n",
      "   4.76983289e-04  9.03906912e-05]\n",
      " [-1.00000000e+00 -1.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
      "  -1.00000000e+00  1.39915291e-03  2.99137973e-05  9.35971038e-05\n",
      "   5.51286910e-04  1.43837533e-04]\n",
      " [ 7.69538292e-06  9.93986941e-06  2.70540818e-06  1.41132123e-05\n",
      "   1.01402702e-05  5.57253952e-05  2.70284305e-04  6.07586582e-04\n",
      "   1.06896891e-03  1.79349119e-03]\n",
      " [ 1.68136103e-05  1.66132104e-05  1.38697260e-05  7.23537378e-05\n",
      "   4.80961444e-06  2.46572890e-05  1.34861592e-04  3.74765164e-04\n",
      "   8.29626399e-04  1.62914465e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(grid_outp[...,0])\n",
    "print(grid_outp[...,1])\n",
    "print(grid_outp[...,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[7.00000000e+01, 5.00000000e+00, 3.30030030e-02],\n",
       "        [5.20000000e+01, 1.00000000e+00, 1.84744123e-02],\n",
       "        [6.90000000e+01, 5.00000000e+00, 5.59559560e-03],\n",
       "        [7.10000000e+01, 8.00000000e+00, 1.52285980e-03],\n",
       "        [7.30000000e+01, 1.00000000e+01, 5.38289641e-04],\n",
       "        [5.00000000e+01, 0.00000000e+00, 1.28455984e-04],\n",
       "        [4.90000000e+01, 0.00000000e+00, 1.01638275e-04],\n",
       "        [7.10000000e+01, 7.00000000e+00, 4.72404336e-05]]),\n",
       " Spectrum(precursor m/z=285.12, 74 fragments between 50.0 and 155.1),\n",
       " Spectrum(precursor m/z=285.12, 14 fragments between 118.1 and 286.1)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_to_score_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.02605932348386438, 5),\n",
       " (0.03442222082648898, 6),\n",
       " (0.06452274444206799, 8),\n",
       " (0.11209947205892355, 8),\n",
       " (0.1623664287234474, 13),\n",
       " (0.23840139483322562, 22),\n",
       " (0.3848047853392426, 33),\n",
       " (0.5657118496972595, 43),\n",
       " (0.7429066000116887, 52),\n",
       " (0.9162835881551422, 62),\n",
       " (0.005728378647648435, 5),\n",
       " (0.009132206272256797, 6),\n",
       " (0.021709608341931294, 8),\n",
       " (0.04213699303551976, 8),\n",
       " (0.06706815456959091, 13),\n",
       " (0.11193900110163978, 21),\n",
       " (0.20943092375678907, 32),\n",
       " (0.3547077252764144, 41),\n",
       " (0.5405889742079147, 49),\n",
       " (0.7662681701490394, 59),\n",
       " (0.9839733090233771, 12),\n",
       " (0.9972879869804555, 12),\n",
       " (0.9955911964844311, 12),\n",
       " (0.964456618462334, 13),\n",
       " (0.9148682500738545, 13),\n",
       " (0.8527410050476982, 13),\n",
       " (0.7035701317343943, 11),\n",
       " (0.4606751332163862, 11),\n",
       " (0.23167265520749364, 10),\n",
       " (0.10444423283199249, 9),\n",
       " (0.3253888505462898, 3),\n",
       " (0.32565130293613376, 4),\n",
       " (0.27739187239428803, 4),\n",
       " (0.196922979415211, 5),\n",
       " (0.14655759650837452, 4),\n",
       " (0.15012987464297978, 4),\n",
       " (0.18799849781377598, 3),\n",
       " (0.2206754137351674, 3),\n",
       " (0.21678727298502343, 3),\n",
       " (0.1736764651693238, 3),\n",
       " (0.2803876444050339, 3),\n",
       " (0.28954309689986785, 4),\n",
       " (0.2815979331727658, 4),\n",
       " (0.2644123099142414, 5),\n",
       " (0.2638242114020741, 4),\n",
       " (0.30587070300046615, 4),\n",
       " (0.3932062351594757, 3),\n",
       " (0.46129148121763963, 3),\n",
       " (0.45319428391184285, 3),\n",
       " (0.3631612671054422, 3),\n",
       " (0.16301333071280036, 3),\n",
       " (0.18228228304506386, 4),\n",
       " (0.2302007689885565, 4),\n",
       " (0.301662864449876, 5),\n",
       " (0.36819431557101434, 6),\n",
       " (0.4535161664554394, 7),\n",
       " (0.5897615680477188, 6),\n",
       " (0.6917576113253484, 6),\n",
       " (0.6797290156402285, 6),\n",
       " (0.5449164970925856, 6),\n",
       " (0.06754932488785412, 3),\n",
       " (0.09096054382178023, 4),\n",
       " (0.16892941336504158, 4),\n",
       " (0.2886375221021771, 4),\n",
       " (0.3901755947492616, 6),\n",
       " (0.49286117679990515, 6),\n",
       " (0.643837498892649, 5),\n",
       " (0.7550776433116079, 5),\n",
       " (0.7418562876220318, 5),\n",
       " (0.5945576860956281, 5),\n",
       " (0.03550470681343969, 2),\n",
       " (0.059783750716123366, 3),\n",
       " (0.1458726603296392, 3),\n",
       " (0.2787256093156955, 3),\n",
       " (0.38950881958186523, 5),\n",
       " (0.49573958410579966, 6),\n",
       " (0.6484611605962343, 5),\n",
       " (0.7605079214183046, 5),\n",
       " (0.747288657669695, 5),\n",
       " (0.5990919065570508, 5),\n",
       " (0.03091935041736776, 3),\n",
       " (0.05530458074701109, 4),\n",
       " (0.1424876064042804, 4),\n",
       " (0.2771179319506203, 4),\n",
       " (0.38914824082864996, 6),\n",
       " (0.4958379854626962, 7),\n",
       " (0.6487628868777758, 6),\n",
       " (0.7609500475328825, 6),\n",
       " (0.7479174285820706, 6),\n",
       " (0.5999513969345318, 6),\n",
       " (0.03052316852970554, 4),\n",
       " (0.05491251694943796, 5),\n",
       " (0.1421782226108839, 5),\n",
       " (0.2769496253269068, 5),\n",
       " (0.38907382265073054, 7),\n",
       " (0.4958236684336057, 8),\n",
       " (0.6489391047517403, 9),\n",
       " (0.7618133317548061, 9),\n",
       " (0.750578843524467, 9),\n",
       " (0.6055264315574215, 9),\n",
       " (0.029603123813878224, 4),\n",
       " (0.053890140383776236, 5),\n",
       " (0.14091945852137328, 5),\n",
       " (0.27534800013161287, 5),\n",
       " (0.3871430613942561, 7),\n",
       " (0.49362269699819666, 9),\n",
       " (0.6469131257822911, 10),\n",
       " (0.7625999087929901, 12),\n",
       " (0.7602853497651543, 13),\n",
       " (0.6304151178882524, 13),\n",
       " (0.027280698925960484, 4),\n",
       " (0.05011121941037548, 5),\n",
       " (0.13201029171089237, 5),\n",
       " (0.2585328973520579, 5),\n",
       " (0.3637347936790605, 9),\n",
       " (0.4643617237500311, 11),\n",
       " (0.6112304461130764, 14),\n",
       " (0.7307022970907889, 17),\n",
       " (0.7574799639292878, 19),\n",
       " (0.6837759540691751, 21),\n",
       " (0.018578113842490567, 4),\n",
       " (0.03423933650429114, 5),\n",
       " (0.09044927651652865, 5),\n",
       " (0.17729683382068442, 5),\n",
       " (0.2495076290985187, 10),\n",
       " (0.3195041406907525, 12),\n",
       " (0.4257086042407531, 17),\n",
       " (0.5289690549335558, 21),\n",
       " (0.6052136753365461, 24),\n",
       " (0.6524268980909272, 28),\n",
       " (0.007656577865062448, 3),\n",
       " (0.014474436182260391, 4),\n",
       " (0.039011311888466765, 4),\n",
       " (0.07693805165809929, 4),\n",
       " (0.10845614220175451, 8),\n",
       " (0.140074509231064, 10),\n",
       " (0.19259448375340726, 17),\n",
       " (0.2624777688010775, 21),\n",
       " (0.36352361022051916, 23),\n",
       " (0.4987666878378979, 28),\n",
       " (0.0024967290400113944, 1),\n",
       " (0.00475908252709964, 2),\n",
       " (0.012891826724626455, 2),\n",
       " (0.02546106611463418, 2),\n",
       " (0.03590345992901354, 3),\n",
       " (0.04756717316028175, 5),\n",
       " (0.07110794240549774, 12),\n",
       " (0.11913599618669249, 15),\n",
       " (0.2201939750988474, 17),\n",
       " (0.3782882134620023, 22),\n",
       " (0.0007131611955928424, 1),\n",
       " (0.0013647843540335325, 2),\n",
       " (0.003695078008719369, 2),\n",
       " (0.007300772952064788, 2),\n",
       " (0.01029565245674454, 3),\n",
       " (0.01478083907932279, 4),\n",
       " (0.02693985200446107, 9),\n",
       " (0.06274760356161034, 12),\n",
       " (0.15135941764418745, 15),\n",
       " (0.2964442765612651, 21),\n",
       " (0.000145172750425737, 1),\n",
       " (0.0002804121934898408, 2),\n",
       " (0.0007582588791025088, 2),\n",
       " (0.001499646304720232, 2),\n",
       " (0.0021144696996429416, 2),\n",
       " (0.003991928374963191, 3),\n",
       " (0.010769070960276118, 8),\n",
       " (0.03601740509775366, 11),\n",
       " (0.10287589502063177, 14),\n",
       " (0.21536651877089516, 19),\n",
       " (0.000881615280381087, 1),\n",
       " (0.004762324010920562, 5),\n",
       " (0.02149939372559689, 8),\n",
       " (0.06738470109463335, 11),\n",
       " (0.147495681244269, 16),\n",
       " (0.9196858972165044, 5),\n",
       " (0.9344342253308717, 5),\n",
       " (0.949508810526784, 6),\n",
       " (0.9449139730647481, 7),\n",
       " (0.914273330642831, 9),\n",
       " (0.8606585168856816, 11),\n",
       " (0.7167150238266885, 11),\n",
       " (0.4763403850321299, 11),\n",
       " (0.24760768623975052, 10),\n",
       " (0.12128119428112098, 9),\n",
       " (0.9104562630765752, 6),\n",
       " (0.925046419223635, 6),\n",
       " (0.9401325513587561, 7),\n",
       " (0.9362376725832205, 8),\n",
       " (0.9085874605394053, 12),\n",
       " (0.8628973181495476, 18),\n",
       " (0.7332619772611648, 20),\n",
       " (0.5052153714108577, 20),\n",
       " (0.28004356266318386, 19),\n",
       " (0.15796646168206246, 18)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/947000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 947000/947000 [01:37<00:00, 9744.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to collect matching pairs:  97.95659852027893\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "start_collect_peaks = time.time()\n",
    "queries_npy = [q.peaks.to_numpy.astype('float32') for q in queries]\n",
    "references_npy = [q.peaks.to_numpy.astype('float32') for q in references]\n",
    "\n",
    "def fn(spectrum_1, spectrum_2):\n",
    "    matching_pairs = collect_peak_pairs(\n",
    "                spectrum_1, \n",
    "                spectrum_2, \n",
    "                tolerance=0.1,\n",
    "                shift=0.0, \n",
    "                mz_power=0.0,\n",
    "                intensity_power=1.0\n",
    "    ) \n",
    "    if matching_pairs is not None:\n",
    "        return score_best_matches(matching_pairs, spectrum_1, spectrum_2, 0.0, 1.0)\n",
    "    \n",
    "total_len = len(references_npy) * len(queries_npy)\n",
    "scores = Parallel(-1)(delayed(fn)(spectrum_1, spectrum_2)\n",
    "                      for (spectrum_1, spectrum_2) in \n",
    "                      tqdm(product(references_npy,queries_npy), total=total_len))\n",
    "\n",
    "end_collect_peaks = time.time()\n",
    "print(\"Time to collect matching pairs: \", end_collect_peaks - start_collect_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectra_peaks_to_tensor(spectra: list, fill: float):\n",
    "    sp_max_shape = max(len(s.peaks) for s in spectra)\n",
    "    sp = np.full((len(spectra), sp_max_shape, 2), fill, 'float32')\n",
    "    batch = np.zeros(len(spectra),dtype=np.uint64)\n",
    "    for i, s in enumerate(spectra):\n",
    "        sp[i, :len(s.peaks)] = s.peaks.to_numpy\n",
    "        batch[i] = len(s.peaks)\n",
    "    return sp, batch\n",
    "\n",
    "# queries = large_references[:1000]\n",
    "# references = large_references[1000:]\n",
    "\n",
    "references_batch, references_batch_size \\\n",
    "    = spectra_peaks_to_tensor(references, fill=-1e6)\n",
    "queries_batch, queries_batch_size \\\n",
    "    = spectra_peaks_to_tensor(queries, fill=-1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/references_mz.npy', references_batch[...,0])\n",
    "np.save('data/references_int.npy', references_batch[...,1])\n",
    "np.save('data/queries_mz.npy', queries_batch[...,0])\n",
    "np.save('data/queries_int.npy', queries_batch[...,1])\n",
    "# np.save('data/scores_100x100.npy', np.array(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/scores_100x100.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m load_scores_true \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mdata/scores_100x100.npy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(load_scores_true)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(load_scores_true\u001b[39m.\u001b[39mshape, load_scores_true\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/pb2/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/scores_100x100.npy'"
     ]
    }
   ],
   "source": [
    "load_scores_true = np.load('data/scores_100x100.npy')\n",
    "print(load_scores_true)\n",
    "print(load_scores_true.shape, load_scores_true.dtype)\n",
    "print(np.sort(load_scores_true[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 5.0000000e+00 2.9956270e-06 1.0000000e+00]\n",
      " [0.0000000e+00 6.0000000e+00 7.0604798e-04 5.0000000e+00]\n",
      " [0.0000000e+00 7.0000000e+00 2.6819189e-03 1.0000000e+01]\n",
      " ...\n",
      " [7.6410000e+03 9.9700000e+02 5.7682420e-05 1.0000000e+00]\n",
      " [7.6410000e+03 9.9800000e+02 2.6733984e-05 1.0000000e+00]\n",
      " [7.6410000e+03 9.9900000e+02 7.2767034e-06 1.0000000e+00]]\n",
      "(65748867, 4) float32\n",
      "[    0.     0.     0. ... 91697. 91697. 91697.]\n"
     ]
    }
   ],
   "source": [
    "load_scores = np.load('data/results.npy')\n",
    "print(load_scores)\n",
    "print(load_scores.shape, load_scores.dtype)\n",
    "print(np.sort(load_scores[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.051981872"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_scores.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1740258,) (22970,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine/cpp/main.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(load_scores[:,\u001b[39m1\u001b[39;49m] \u001b[39m-\u001b[39;49m load_scores_true[:\u001b[39mlen\u001b[39;49m(load_scores[:,\u001b[39m1\u001b[39;49m]),\u001b[39m1\u001b[39;49m])\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1740258,) (22970,) "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(load_scores[:,1] - load_scores_true[:len(load_scores[:,1]),1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
