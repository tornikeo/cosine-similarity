{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip uninstall cudams -q -y\n",
    "! pip install git+https://github.com/tornikeo/cosine-similarity.git@dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cudams.utils import \\\n",
    "    argbatch, mkdir, get_ref_spectra_from_df\n",
    "import math\n",
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numba\n",
    "from numba import cuda\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "assert cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cudams.similarity.kernels import compile_cuda_cosine_greedy_kernel\n",
    "\n",
    "match_limit = 1024\n",
    "max_peaks = 1024\n",
    "batch_size = 2048 * 8# Works best on rtx4090. Use half for most other less advanced hardware (i.e. T4)\n",
    "\n",
    "# IMPORTANT! Keep this value above .5, especially for large spectra files. The score results might get *extremely* large (100s of GB)\n",
    "# for low sparsity thresholds. This value dictates the minimum cosine greedy similarity threshold at which we keep the result\n",
    "# similarity results with a score below threshold are discarded.\n",
    "threshold = .75\n",
    "\n",
    "kernel = compile_cuda_cosine_greedy_kernel(\n",
    "    tolerance=.1,\n",
    "    shift=0,\n",
    "    mz_power=0,\n",
    "    int_power=1,\n",
    "    match_limit=match_limit,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run a pairwise cosine similarity on the entirety of the GNPS dataset (around 500_000 spectra).\n",
    "\n",
    "Parsing these many spectra takes a while, so I already have a pickled version of the same dataset ready to go in `ALL_GNPS.pickle`.\n",
    "\n",
    "Alternatively, you can use `ALL_GNPS.mgf` and wait for the parsing to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cudams.utils import download\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed\n",
    "from matchms.filtering import default_filters, normalize_intensities, reduce_to_number_of_peaks\n",
    "from matchms.importing import load_from_mgf\n",
    "import pickle\n",
    "\n",
    "## Load raw MGF\n",
    "# Ignore all logging from inside of joblib (this saves the notebook from being overrun with warnings from matchms)\n",
    "# import os\n",
    "# os.environ['PYTHONWARNINGS']= 'ignore'\n",
    "\n",
    "# spectra_file = download('ALL_GNPS.mgf')\n",
    "# def parse_spectrum(spectrum):\n",
    "#     # spectrum = default_filters(spectrum)\n",
    "#     spectrum = reduce_to_number_of_peaks(spectrum, n_max=max_peaks)\n",
    "#     spectrum = normalize_intensities(spectrum)\n",
    "#     return spectrum\n",
    "\n",
    "# spectrums = Parallel(-1)(delayed(parse_spectrum)(spec) for spec in tqdm(load_from_mgf(spectra_file)))\n",
    "# spectrums = [spe for spe in spectrums if spe is not None]\n",
    "\n",
    "## Download and read prepared pickle\n",
    "spectra_file = download('ALL_GNPS.pickle')\n",
    "spectrums = tuple(pickle.load(open(spectra_file, 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise similarity between all\n",
    "references, queries = spectrums, spectrums\n",
    "\n",
    "# references = references[:10_000]\n",
    "# queries = queries[:10_000]\n",
    "\n",
    "print(f\"We have {len(references) + len(queries):.3e} spectra\")\n",
    "print(f\"Pairwise comparisons have {len(references)*len(queries):.3e} pairs in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cudams.utils import spectra_peaks_to_tensor\n",
    "from itertools import product\n",
    "dtype = np.float32\n",
    "padding = None\n",
    "\n",
    "batches_r = []\n",
    "for bstart, bend in tqdm(\n",
    "    argbatch(references, batch_size), desc=\"Batch all references\",\n",
    "    total=len(references)//batch_size\n",
    "):\n",
    "    rbatch = references[bstart:bend]\n",
    "    rspec, rlen = spectra_peaks_to_tensor(rbatch, dtype=dtype)\n",
    "    batches_r.append([rspec, rlen, bstart, bend])\n",
    "\n",
    "batches_q = []\n",
    "for bstart, bend in tqdm(\n",
    "    argbatch(queries, batch_size), desc=\"Batch all queries\",\n",
    "    total=len(queries)//batch_size\n",
    "):\n",
    "    qbatch = queries[bstart:bend]\n",
    "    qspec, qlen = spectra_peaks_to_tensor(qbatch, dtype=dtype)\n",
    "    batches_q.append([qspec, qlen, bstart, bend])\n",
    "    \n",
    "batched_inputs = tuple(product(batches_r, batches_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "host = torch.device('cpu')\n",
    "\n",
    "! rm -rf data/output\n",
    "! mkdir -p data/output\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_i in tqdm(range(len(batched_inputs))):\n",
    "        (rspec, rlen, rstart, rend), (qspec, qlen, qstart, qend) = batched_inputs[\n",
    "            batch_i\n",
    "        ]\n",
    "        \n",
    "        lens = torch.zeros(2, batch_size, dtype=torch.int32)\n",
    "        lens[0, :len(rlen)] = torch.from_numpy(rlen)\n",
    "        lens[1, :len(qlen)] = torch.from_numpy(qlen)\n",
    "        \n",
    "        lens = lens.to(device)\n",
    "        \n",
    "        rspec = torch.from_numpy(rspec).to(device)\n",
    "        qspec = torch.from_numpy(qspec).to(device)\n",
    "    \n",
    "        rspec = cuda.as_cuda_array(rspec)\n",
    "        qspec = cuda.as_cuda_array(qspec)\n",
    "        lens = cuda.as_cuda_array(lens)\n",
    "            \n",
    "        out = torch.empty(3, batch_size, batch_size, dtype=torch.float32, device=device)\n",
    "        out = cuda.as_cuda_array(out)\n",
    "        \n",
    "        kernel(rspec, qspec, lens, out)\n",
    "        \n",
    "        out = torch.as_tensor(out, device=device)\n",
    "        mask = out[0] >= threshold\n",
    "        row, col = torch.nonzero(mask, as_tuple=True)\n",
    "        rabs = rstart + row\n",
    "        qabs = qstart + col\n",
    "        score, matches, overflow = out[:, mask].to(host)\n",
    "        \n",
    "        np.savez_compressed(\n",
    "            f'data/output/{rstart}-{rend}-{qstart}-{qend}.npz', \n",
    "            rabs=rabs.int().to(host), \n",
    "            qabs=qabs.int().to(host), \n",
    "            score=score.float(),\n",
    "            matches=matches.int(),\n",
    "            overflow=overflow.bool()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! du -hs data/output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "! du -hs data/output/\n",
    "\n",
    "total_size = sum(f.stat().st_size for f in Path('data/output').glob('**/*') if f.is_file())\n",
    "print(f'Total file size {total_size/1e9:.3f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qabs = []\n",
    "rabs = []\n",
    "score = []\n",
    "matches = []\n",
    "overflow = []\n",
    "for file in tqdm(Path('data/output').glob('*.npz')):\n",
    "    bunch = np.load(file)\n",
    "    qabs += [bunch['qabs']]\n",
    "    rabs += [bunch['rabs']]\n",
    "    score += [bunch['score']]\n",
    "    matches += [bunch['matches']]\n",
    "    overflow += [bunch['overflow']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qabs = np.concatenate(qabs)\n",
    "rabs = np.concatenate(rabs)\n",
    "score = np.concatenate(score)\n",
    "matches = np.concatenate(matches)\n",
    "overflow = np.concatenate(overflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we want to query these absolute query IDs, and sort their results\n",
    "query = np.array([1, 42, 121, 99_999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "for q in query:\n",
    "    idx = qabs == q\n",
    "    res = np.stack([rabs[idx], score[idx], matches[idx], overflow[idx]],axis=1)\n",
    "    res = pd.DataFrame(res, columns='ReferenceID Score Matches Overflow'.split())\n",
    "    print(f\"Similarity for chemical with QueryID={q}\")\n",
    "    display(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
