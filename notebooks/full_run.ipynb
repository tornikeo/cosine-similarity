{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbutils import chdir_to_root\n",
    "chdir_to_root()\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cudams.utils import argbatch, mkdir\n",
    "from cudams.data import get_ref_spectra_from_df\n",
    "from cudams.kernel import compile\n",
    "from cudams.utils import name2idx\n",
    "from cudams.cosine import similarity\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from cudams.data import spectra_peaks_to_tensor\n",
    "from cudams.processor import Config\n",
    "from numba import cuda\n",
    "from itertools import product\n",
    "from time import perf_counter\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from multiprocessing import shared_memory\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "assert cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define constants\n",
    "tolerance: float = 0.1\n",
    "shift: float = 0\n",
    "mz_power: float = 0\n",
    "int_power: float = 1\n",
    "\n",
    "## How many pairs per batch. Has to be a power of 2.\n",
    "# Hardware specific - An RTX2070 works best at around 1024 * 2\n",
    "# But Colab T4 GPU might work best at 1024 * 4\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# MAX NUMBER OF PEAKS during filtering. Due to nature of matrices, having large number of \n",
    "# peaks will increase memory requirements. After 1024, this has diminishing benefits, as \n",
    "# smaller and smaller (likely noisy) peaks are taken into consideration when running similarity.\n",
    "MAX_PEAKS = 1024\n",
    "\n",
    "# MATCH_LIMIT specifies max how many mz-mz pairs we could consider for each RQ pair, before we sort and filter. \n",
    "# E.g. a value of 256 usually causes around ~0.003% of RQ pairs to \"overflow\".\n",
    "# The overflown RQ scores will be strictly less than or equal to perfectly accurate score.\n",
    "# The mean absolute difference at 256, for all overflown pairs is on the order of ~1e-3\n",
    "# Small values of MATCH_LIMIT (e.g. 128, 64,) cause a dramatic speedup in the processing speed.\n",
    "MATCH_LIMIT = 1024\n",
    "\n",
    "# Since Greedy cosine is an unstable algorithm, because approximate mz-mz values do not\n",
    "# result in approximately the same scores and number of matches.\n",
    "# So we need to use fp64 to minimize the deviation as much as possible.\n",
    "# Using float32 causes a significant speedup in the processing speed.\n",
    "dtype = 'float32'\n",
    "\n",
    "# Data path\n",
    "reference_csv_file = Path(\"data/input/example_dataset_tornike.csv\")\n",
    "query_csv_file = Path(\"data/input/example_dataset_tornike.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40960/40960 [00:12<00:00, 3283.30it/s]\n",
      "100%|██████████| 40960/40960 [00:10<00:00, 4091.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from cudams.processor import CudaCosineGreedy, CpuCosineGreedy\n",
    "from collections import defaultdict\n",
    "from matchms import calculate_scores\n",
    "from matchms.similarity import CosineGreedy\n",
    "from tqdm import tqdm\n",
    "from matchms.filtering import normalize_intensities, select_by_mz, select_by_relative_intensity, reduce_to_number_of_peaks, \\\n",
    "    require_minimum_number_of_peaks\n",
    "from cudams.utils import mute_stdout\n",
    "\n",
    "def process_spectrum(spectrum: np.ndarray) -> np.ndarray:\n",
    "    spectrum = select_by_mz(spectrum, mz_from=10.0, mz_to=1000.0)\n",
    "    spectrum = normalize_intensities(spectrum)\n",
    "    spectrum = select_by_relative_intensity(spectrum, intensity_from=0.001)\n",
    "    spectrum = reduce_to_number_of_peaks(spectrum, n_max=MAX_PEAKS)\n",
    "    spectrum = require_minimum_number_of_peaks(spectrum, n_required=5)\n",
    "    return spectrum\n",
    "\n",
    "ref_spectra_df_path = Path(reference_csv_file)\n",
    "ref_spectra_df = pd.read_csv(ref_spectra_df_path)\n",
    "references = get_ref_spectra_from_df(ref_spectra_df, \n",
    "                                    spectrum_processor=process_spectrum,\n",
    "                                    limit=BATCH_SIZE * 40)\n",
    "\n",
    "query_spectra_df_path = Path(query_csv_file)\n",
    "query_spectra_df = pd.read_csv(query_spectra_df_path)\n",
    "queries = get_ref_spectra_from_df(query_spectra_df, \n",
    "                                spectrum_processor=process_spectrum,\n",
    "                                limit=BATCH_SIZE * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# references = references[-BATCH_SIZE:]\n",
    "# queries = queries[-BATCH_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch all references: 40it [00:00, 61.47it/s]\n",
      "Batch all queries: 40it [00:00, 54.36it/s]\n",
      "100%|██████████| 1600/1600 [03:03<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size 0.15GB\n",
      "Num of output 6155331\n",
      "Pairs processed 1.6e+09\n",
      "pairs per hr 3.1e+10\n",
      "Full run (100kx1.5mln) est: 4.804hrs\n",
      "Full run (100kx1.5mln) est GBs: 14.36GB\n"
     ]
    }
   ],
   "source": [
    "from cudams.processor import CudaCosineGreedy\n",
    "from tqdm import tqdm\n",
    "\n",
    "refs = list([r.peaks.to_numpy for r in references])\n",
    "ques = list([q.peaks.to_numpy for q in queries])\n",
    "\n",
    "rlims = argbatch(refs, BATCH_SIZE)\n",
    "qlims = argbatch(ques, BATCH_SIZE)\n",
    "R = len(references)\n",
    "Q = len(queries)\n",
    "\n",
    "batches_rq = list(product(rlims, qlims))\n",
    "\n",
    "cosine = CudaCosineGreedy(\n",
    "    tolerance=tolerance,\n",
    "    mz_power=0,\n",
    "    intensity_power=1, \n",
    "    shift=0,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    match_limit=MATCH_LIMIT,\n",
    ")\n",
    "cosine.compile()\n",
    "t = perf_counter()\n",
    "ri, qi, out, overflows = cosine.matrix(\n",
    "    references=references, \n",
    "    queries=queries, \n",
    "    array_type=\"sparse\",\n",
    "    sparse_threshold=.75,\n",
    ")\n",
    "t = perf_counter() - t\n",
    "sum_nbytes = sum(o.nbytes for o in [ri, qi, out, overflows])\n",
    "print(f\"Output size {sum_nbytes / 1e9:.2f}GB\")\n",
    "print(f\"Num of output {len(ri)}\")\n",
    "print(f\"Pairs processed {len(references) * len(queries):.1e}\")\n",
    "n_pairs = len(references) * len(queries)\n",
    "perh = (n_pairs / t) * 3600\n",
    "\n",
    "print(f\"pairs per hr {perh:.1e}\")\n",
    "print(f\"Full run (100kx1.5mln) est: {100_000 * 1_500_000 / perh:.3f}hrs\")\n",
    "print(f\"Full run (100kx1.5mln) est GBs: {(sum_nbytes/n_pairs)*(100_000*1_500_000)*1e-9:.2f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tornikeo/miniconda3/envs/pb2/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 64 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home/tornikeo/miniconda3/envs/pb2/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda, types\n",
    "\n",
    "@cuda.jit\n",
    "def threshold_kernel(\n",
    "    scores,\n",
    "    threshold: float,\n",
    "    out,\n",
    "):\n",
    "    i, j = cuda.grid(2)\n",
    "    v = 0\n",
    "    if i < BATCH_SIZE and j < BATCH_SIZE:\n",
    "        v = scores[i,j,0] >= threshold\n",
    "    out[i,j] = v\n",
    "    \n",
    "@cuda.reduce\n",
    "def sum_kernel(\n",
    "    a, b,\n",
    "):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "THREADS_PER_BLOCK = (32, 32)\n",
    "BLOCKS_PER_GRID_X = math.ceil(R / THREADS_PER_BLOCK[0])\n",
    "BLOCKS_PER_GRID_Y = math.ceil(Q / THREADS_PER_BLOCK[1])\n",
    "BLOCKS_PER_GRID = (BLOCKS_PER_GRID_X, BLOCKS_PER_GRID_Y)\n",
    "\n",
    "\n",
    "scores_cu = cuda.to_device(out)\n",
    "threshold = .85\n",
    "scores_thr_cu = cuda.device_array(\n",
    "    (BATCH_SIZE, BATCH_SIZE),\n",
    "    dtype='uint32',\n",
    ")\n",
    "threshold_kernel[THREADS_PER_BLOCK, BLOCKS_PER_GRID](\n",
    "    scores_cu,\n",
    "    threshold,\n",
    "    scores_thr_cu,   \n",
    ")\n",
    "\n",
    "s = int(sum_kernel(\n",
    "    scores_thr_cu.ravel(),\n",
    "))\n",
    "\n",
    "r = cuda.device_array(s,'int32')\n",
    "c = cuda.device_array(s,'int32')\n",
    "v = cuda.device_array(s,'float32')\n",
    "\n",
    "assert s == (out[...,0] >= threshold).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_r = np.random.uniform(size=(BATCH_SIZE, BATCH_SIZE,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.66 ms ± 99.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "r,c = np.nonzero((out_r[...,0]>=threshold))\n",
    "v = out_r[r,c,0]\n",
    "v.sum()\n",
    "# assert v.sum() < r.sum() + c.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pb2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
