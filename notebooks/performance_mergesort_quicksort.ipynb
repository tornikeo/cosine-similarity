{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tornikeo/Documents/work/scalexa/pangeaai/optimize-cosine'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbutils import chdir_to_root\n",
    "chdir_to_root()\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cudams.utils import argbatch, mkdir\n",
    "from cudams.data import get_ref_spectra_from_df\n",
    "from cudams.kernel import compile\n",
    "from cudams.utils import name2idx\n",
    "from cudams.cosine import similarity\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from cudams.data import spectra_peaks_to_tensor\n",
    "from cudams.processor import Config\n",
    "from numba import cuda\n",
    "from itertools import product\n",
    "from time import perf_counter\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from multiprocessing import shared_memory\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from typing import Tuple\n",
    "from matchms.typing import SpectrumType\n",
    "from matchms.similarity.BaseSimilarity import BaseSimilarity\n",
    "from matchms.similarity.spectrum_similarity_functions import (collect_peak_pairs,\n",
    "                                            score_best_matches)\n",
    "from matchms.similarity import CosineGreedy as OriginalCosineGreedy\n",
    "\n",
    "assert cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define constants\n",
    "tolerance: float = 0.1\n",
    "shift: float = 0\n",
    "mz_power: float = 0\n",
    "int_power: float = 1\n",
    "\n",
    "## How many pairs per batch. Has to be a power of 2.\n",
    "# Hardware specific - An RTX2070 works best at around 1024 * 2\n",
    "# But Colab T4 GPU might work best at 1024 * 4\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "# MAX NUMBER OF PEAKS \n",
    "MAX_PEAKS = 1024\n",
    "\n",
    "# MATCH_LIMIT specifies max how many mz-mz pairs we could consider for each RQ pair, before we sort and filter. \n",
    "# E.g. a value of 256 usually causes around ~0.003% of RQ pairs to \"overflow\".\n",
    "# The overflown RQ scores will be strictly less than or equal to perfectly accurate score.\n",
    "# The mean absolute difference at 256, for all overflown pairs is on the order of ~1e-3\n",
    "# Small values of MATCH_LIMIT (e.g. 128, 64,) cause a dramatic speedup in the processing speed.\n",
    "MATCH_LIMIT = 1024 * 2\n",
    "\n",
    "## GPU-specific constants\n",
    "THREADS_PER_BLOCK = (32, 32)\n",
    "BLOCKS_PER_GRID_X = math.ceil(BATCH_SIZE / THREADS_PER_BLOCK[0])\n",
    "BLOCKS_PER_GRID_Y = math.ceil(BATCH_SIZE / THREADS_PER_BLOCK[1])\n",
    "BLOCKS_PER_GRID = (BLOCKS_PER_GRID_X, BLOCKS_PER_GRID_Y)\n",
    "\n",
    "# Since Greedy cosine is an unstable algorithm, because approximate mz-mz values do not\n",
    "# result in approximately the same scores and number of matches.\n",
    "# So we need to use fp64 to minimize the deviation as much as possible.\n",
    "# Using float32 causes a significant speedup in the processing speed.\n",
    "dtype = 'float32'\n",
    "\n",
    "# Data path\n",
    "reference_csv_file = Path(\"data/input/test_set_cosine.csv\")\n",
    "query_csv_file = Path(\"data/input/test_set_cosine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:02<00:00, 442.42it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 4684.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from cudams.processor import CudaCosineGreedy, CpuCosineGreedy\n",
    "from collections import defaultdict\n",
    "from matchms import calculate_scores\n",
    "from matchms.similarity import CosineGreedy\n",
    "from tqdm import tqdm\n",
    "from matchms.filtering import normalize_intensities, select_by_mz, select_by_relative_intensity, reduce_to_number_of_peaks, \\\n",
    "    require_minimum_number_of_peaks\n",
    "from cudams.utils import mute_stdout\n",
    "\n",
    "def process_spectrum(spectrum: np.ndarray) -> np.ndarray:\n",
    "    # spectrum = select_by_mz(spectrum, mz_from=10.0, mz_to=1000.0)\n",
    "    # spectrum = normalize_intensities(spectrum)\n",
    "    # spectrum = select_by_relative_intensity(spectrum, intensity_from=0.001)\n",
    "    # spectrum = reduce_to_number_of_peaks(spectrum, n_max=1000)\n",
    "    spectrum = reduce_to_number_of_peaks(spectrum, n_max=MAX_PEAKS)\n",
    "    # spectrum = require_minimum_number_of_peaks(spectrum, n_required=5)\n",
    "    return spectrum\n",
    "\n",
    "ref_spectra_df_path = Path(reference_csv_file)\n",
    "ref_spectra_df = pd.read_csv(ref_spectra_df_path)\n",
    "references = get_ref_spectra_from_df(ref_spectra_df, \n",
    "                                    spectrum_processor=process_spectrum,\n",
    "                                    limit=BATCH_SIZE * 2,)\n",
    "\n",
    "query_spectra_df_path = Path(query_csv_file)\n",
    "query_spectra_df = pd.read_csv(query_spectra_df_path)\n",
    "queries = get_ref_spectra_from_df(query_spectra_df, \n",
    "                                spectrum_processor=process_spectrum,\n",
    "                                limit=BATCH_SIZE * 2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matchms.similarity.CosineGreedy as OriginalCosineGreedy\n",
    "\n",
    "class CosineGreedy(OriginalCosineGreedy):\n",
    "    \"\"\"Stable implementation of original cosine greedy\"\"\"\n",
    "    def __init__(self, tolerance: float = 0.1, mz_power: float = 0, intensity_power: float = 1):\n",
    "        super().__init__(tolerance, mz_power, intensity_power)\n",
    "        \n",
    "    def pair(self, reference: SpectrumType, query: SpectrumType) -> Tuple[float, int]:\n",
    "        \"\"\"Calculate cosine score between two spectra.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        reference\n",
    "            Single reference spectrum.\n",
    "        query\n",
    "            Single query spectrum.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Score\n",
    "            Tuple with cosine score and number of matched peaks.\n",
    "        \"\"\"\n",
    "        def get_matching_pairs():\n",
    "            \"\"\"Get pairs of peaks that match within the given tolerance.\"\"\"\n",
    "            matching_pairs = collect_peak_pairs(spec1, spec2, self.tolerance,\n",
    "                                                shift=0.0, mz_power=self.mz_power,\n",
    "                                                intensity_power=self.intensity_power)\n",
    "            if matching_pairs is None:\n",
    "                return None\n",
    "            # This is the only argument that we change `kind='mergesort'`\n",
    "            matching_pairs = matching_pairs[np.argsort(matching_pairs[:, 2],kind='mergesort')[::-1], :]\n",
    "            return matching_pairs\n",
    "\n",
    "        spec1 = reference.peaks.to_numpy\n",
    "        spec2 = query.peaks.to_numpy\n",
    "        matching_pairs = get_matching_pairs()\n",
    "        if matching_pairs is None:\n",
    "            return np.asarray((float(0), 0), dtype=self.score_datatype)\n",
    "        score = score_best_matches(matching_pairs, spec1, spec2,\n",
    "                                   self.mz_power, self.intensity_power)\n",
    "        return np.asarray(score, dtype=self.score_datatype)\n",
    "\n",
    "\n",
    "similarity_measure = CosineGreedy(tolerance=tolerance, \n",
    "                                mz_power= 0.0, \n",
    "                                intensity_power = 1.0)\n",
    "\n",
    "duration = -perf_counter()\n",
    "scores = calculate_scores(references, queries, similarity_measure, is_symmetric=False)\n",
    "duration += perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of outputs StackedSparseArray array of shape (1024, 1024, 2) containing scores for ('CosineGreedy_score', 'CosineGreedy_matches').\n",
      "Pairs processed 1.0e+06\n",
      "pairs per hr 5.7e+07\n",
      "Full run (100kx1.5mln) est: 2625.623hrs\n",
      "Full run (100kx1.5mln) est GBs: 1591.96GB\n"
     ]
    }
   ],
   "source": [
    "n_pairs = len(references) * len(queries)\n",
    "total_nbytes = scores._scores.data.nbytes\n",
    "print(f\"Num of outputs {scores}\")\n",
    "print(f\"Pairs processed {n_pairs:.1e}\")\n",
    "n_pairs = len(references) * len(queries)\n",
    "pair_per_hr = (n_pairs / duration) * 3600\n",
    "\n",
    "print(f\"pairs per hr {pair_per_hr:.1e}\")\n",
    "print(f\"Full run (100kx1.5mln) est: {100_000 * 1_500_000 / pair_per_hr:.3f}hrs\")\n",
    "print(f\"Full run (100kx1.5mln) est GBs: {(total_nbytes/n_pairs)*(100_000*1_500_000)*1e-9:.2f}GB\")\n",
    "mergesort_pairs_perh = pair_per_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.similarity import CosineGreedy\n",
    "\n",
    "similarity_measure = CosineGreedy(tolerance=tolerance, \n",
    "                                mz_power= 0.0, \n",
    "                                intensity_power = 1.0)\n",
    "duration = -perf_counter()\n",
    "scores = calculate_scores(references, queries, similarity_measure, is_symmetric=False)\n",
    "duration += perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of outputs StackedSparseArray array of shape (1024, 1024, 2) containing scores for ('CosineGreedy_score', 'CosineGreedy_matches').\n",
      "Pairs processed 1.0e+06\n",
      "pairs per hr 5.8e+07\n",
      "Full run (100kx1.5mln) est: 2586.891hrs\n",
      "Full run (100kx1.5mln) est GBs: 1591.96GB\n"
     ]
    }
   ],
   "source": [
    "n_pairs = len(references) * len(queries)\n",
    "total_nbytes = scores._scores.data.nbytes\n",
    "print(f\"Num of outputs {scores}\")\n",
    "print(f\"Pairs processed {n_pairs:.1e}\")\n",
    "n_pairs = len(references) * len(queries)\n",
    "pair_per_hr = (n_pairs / duration) * 3600\n",
    "\n",
    "print(f\"pairs per hr {pair_per_hr:.1e}\")\n",
    "print(f\"Full run (100kx1.5mln) est: {100_000 * 1_500_000 / pair_per_hr:.3f}hrs\")\n",
    "print(f\"Full run (100kx1.5mln) est GBs: {(total_nbytes/n_pairs)*(100_000*1_500_000)*1e-9:.2f}GB\")\n",
    "quicksort_pairs_per_hr = pair_per_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_speed = 100 * (1 - (mergesort_pairs_perh / quicksort_pairs_per_hr))\n",
    "print(f\"Mergesort has {relative_speed:.2f}% the processing speed of quicksort\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pb2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
